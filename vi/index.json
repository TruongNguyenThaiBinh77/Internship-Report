[{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Trương Nguyễn Thái Bình\nSố điện thoại: 0869371050\nEmail: binhtntse182370@fpt.edu.vn\nTrường: Đại học FPT Thành phố Hồ Chí Minh\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/3-blogstranslated/3.4-blog4/","title":"Blog 4","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/3-blogstranslated/3.5-blog5/","title":"Blog 5","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/3-blogstranslated/3.6-blog6/","title":"Blog 6","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"Chuẩn bị tài nguyên","tags":[],"description":"","content":"Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders\u0026rdquo; Chủ đề (Track 1): GenAI \u0026amp; Data (Trí tuệ nhân tạo tạo sinh \u0026amp; Dữ liệu)\nI. MỤC TIÊU THAM DỰ Việc tham dự sự kiện nhằm cập nhật các xu hướng và giải pháp mới nhất trên AWS, cụ thể tập trung vào 4 mục tiêu chính:\nChiến lược GenAI toàn diện: Nắm bắt cách xây dựng quy trình phát triển phần mềm định hướng AI (AI-DLC) và các chiến lược GenAI mới nhất Bảo mật doanh nghiệp: Hiểu sâu về bảo mật trong GenAI và AI Agents để đảm bảo an toàn dữ liệu Nền tảng dữ liệu: Học cách xây dựng nền tảng dữ liệu thống nhất (Unified Data Foundation) tối ưu cho Analytics và AI Kết nối chuyên gia: Trao đổi trực tiếp với đội ngũ kỹ sư và chuyên gia từ AWS Diễn giả tham gia:\nĐội ngũ AWS: Jun Kai Loke (AI/ML Specialist), Kien Nguyen, Tamelly Lim, Binh Tran, Taiki Dang (Solutions Architects), Michael Armentano (Principal WW GTM Specialist).\nII. NỘI DUNG CHUYÊN MÔN TRỌNG TÂM 1. Nền tảng dữ liệu thống nhất (Unified Data Platform) Để AI hoạt động hiệu quả, dữ liệu cần được xử lý liền mạch. AWS nhấn mạnh mô hình Zero-ETL và phá vỡ các \u0026ldquo;ốc đảo dữ liệu\u0026rdquo; (silos):\nQuy trình End-to-End: Từ thu thập (Ingestion) $\\rightarrow$ Lưu trữ (Storage) $\\rightarrow$ Xử lý (Processing) $\\rightarrow$ Truy cập (Access) $\\rightarrow$ Quản trị (Governance) Hệ sinh thái dịch vụ: Kết hợp chặt chẽ giữa Amazon S3, Glue, Redshift, Lake Formation và OpenSearch Tư duy Self-service: Trao quyền cho các nhóm dự án tự khai thác dữ liệu nhưng vẫn đảm bảo tuân thủ quy chuẩn chung 2. Chiến lược GenAI \u0026amp; Amazon Bedrock Amazon Bedrock: Đóng vai trò trung tâm trong việc lựa chọn mô hình (Foundation Models), triển khai RAG (Retrieval-Augmented Generation), và tối ưu hóa chi phí/độ trễ AgentCore \u0026amp; Amazon Nova: Hỗ trợ mạnh mẽ các framework Agent hiện đại như CrewAI, LangGraph, LlamaIndex, giúp xây dựng các tác vụ tự động hóa phức tạp 3. Bảo mật đa lớp cho GenAI (Securing GenAI) Bảo mật không chỉ nằm ở hạ tầng mà phải áp dụng theo mô hình \u0026ldquo;Defense in Depth\u0026rdquo; (Phòng thủ chiều sâu):\n3 lớp bảo mật: Hạ tầng (Infrastructure) $\\rightarrow$ Mô hình (Model) $\\rightarrow$ Ứng dụng (Application) 5 trụ cột chính: Tuân thủ (Compliance), Quyền riêng tư (Privacy), Kiểm soát (Controls), Quản lý rủi ro (Risk Management), và Khả năng phục hồi (Resilience) Công cụ thực tế: Sử dụng Bedrock Guardrails để kiểm duyệt nội dung đầu ra/đầu vào và OpenTelemetry để giám sát (Observability) 4. AI-Driven Development Lifecycle (AI-DLC) Đây là sự chuyển dịch quan trọng trong tư duy phát triển phần mềm:\nTiến hóa: Chuyển từ AI-Assisted (AI hỗ trợ code) $\\rightarrow$ AI-Driven (AI dẫn dắt) $\\rightarrow$ AI-Managed (AI quản lý vận hành) Thực thi: Tích hợp AI vào mọi khâu: từ IaC (Infrastructure as Code), kiểm thử tự động (Automated Testing) đến quản lý rủi ro 5. Amazon SageMaker – Unified Studio Môi trường hợp nhất cho Data, Analytics và AI, hỗ trợ kiến trúc Lakehouse Tích hợp MLOps toàn diện (Pipelines, Registry, Monitoring) giúp tăng tốc đưa ứng dụng GenAI ra thị trường III. BÀI HỌC \u0026amp; TƯ DUY ĐÚC KẾT Từ các nội dung trên, tôi rút ra được 3 bài học cốt lõi cho việc phát triển dự án:\nTư duy Thiết kế (Design Mindset): Cần xây dựng hệ thống Data \u0026amp; AI theo tư duy \u0026ldquo;End-to-End\u0026rdquo; ngay từ đầu, tránh rời rạc Nguyên tắc quản trị (Governance) phải đi đôi với khả năng tự phục vụ (Self-service) Kiến trúc Kỹ thuật (Technical Architecture): Tận dụng tối đa Zero-ETL (tích hợp S3 $\\leftrightarrow$ Redshift/Aurora/DynamoDB) để giảm thiểu công sức vận hành đường ống dữ liệu Sử dụng AI Agents để tự động hóa quy trình thay vì chỉ dùng AI như một công cụ chat bot thông thường Độ tin cậy và Chính xác: Để giảm ảo giác (Hallucination) của AI, bắt buộc phải phối hợp: Prompt Engineering + RAG + Fine-tuning Quy trình RAG chuẩn: $Input \\rightarrow Embedding \\rightarrow Context \\rightarrow LLM \\rightarrow Output$ IV. KẾ HOẠCH ỨNG DỤNG VÀO CÔNG VIỆC Dựa trên kiến thức đã học, tôi đề xuất các hướng ứng dụng cụ thể:\n1. Đối với dự án hiện tại Tính năng: Thử nghiệm tích hợp AI Agents vào quy trình Chăm sóc khách hàng (Customer Support) và Hỗ trợ đăng ký/đăng nhập An toàn: Áp dụng Bedrock Guardrails và các lớp validate để đảm bảo AI không trả lời các nội dung nhạy cảm hoặc sai lệch 2. Đối với quy trình phát triển (Team \u0026amp; Learning) Mô hình AI-DLC: Phân chia rõ ràng nhiệm vụ: AI chịu trách nhiệm sinh mã nguồn (generate code) và viết tài liệu (docs); con người tập trung vào Review và Approve (phê duyệt) Hạ tầng: Cân nhắc kỹ lưỡng việc sử dụng Serverless (AWS Lambda) cho các tác vụ ngắn hạn so với Container (ECS/Fargate) cho các tác vụ dài hạn/phức tạp 3. Định hướng cá nhân (Vai trò Intern/Developer) Business-First: Luôn đặt câu hỏi \u0026ldquo;Giá trị nghiệp vụ là gì?\u0026rdquo; trước khi viết code hoặc thu thập yêu cầu. Công nghệ phải phục vụ mục tiêu kinh doanh Data Mindset: Nhận thức rõ rằng một nền tảng dữ liệu sạch và có cấu trúc là điều kiện tiên quyết để GenAI hoạt động hiệu quả V. TRẢI NGHIỆM \u0026amp; ĐÁNH GIÁ Điểm nhấn lớn nhất của sự kiện là workshop \u0026ldquo;GenAI-powered App-DB Modernization\u0026rdquo;. Đây là cơ hội quý giá để thực hành hiện đại hóa cơ sở dữ liệu và ứng dụng.\nVề chuyên môn: Tôi đã hiểu rõ cách thiết kế một pipeline dữ liệu hoàn chỉnh và cách cân bằng giữa sức mạnh của AI với sự kiểm soát của con người (Human-in-the-loop) Về công cụ: Đã được tiếp cận thực tế với Amazon Bedrock, AgentCore và SageMaker Unified Studio Về kết nối: Việc trao đổi với các chuyên gia AWS giúp tôi mở rộng góc nhìn về các bài toán thực tế (Use cases) và cách giải quyết vấn đề ở quy mô doanh nghiệp Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của bạn tại đây Tổng kết: GenAI không chỉ là một công cụ, mà đòi hỏi một chiến lược tổng thể từ Dữ liệu, Bảo mật đến Kiến trúc. Việc áp dụng AI Agents và mô hình AI-DLC sẽ là chìa khóa để nâng cao năng suất và thay đổi cách vận hành hệ thống trong tương lai gần.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Đây là báo cáo kỹ thuật toàn diện và nhật ký công việc chi tiết cho chương trình \u0026ldquo;First Cloud Journey\u0026rdquo;. Được thiết kế như một lộ trình phát triển năng lực kéo dài 3 tháng, từ ngày 8 tháng 9 năm 2025 đến ngày 7 tháng 12 năm 2025, báo cáo này mô phỏng quá trình chuyển đổi của một kiến trúc sư hệ thống từ các khái niệm cơ bản về đám mây sang việc triển khai các kiến trúc hiện đại, phức tạp trên Amazon Web Services (AWS).\nTừ Tuần 8 trở đi, song song với việc học AWS, tôi bắt đầu tham gia dự án Voltgo - một nền tảng thuê xe điện. Với vai trò Frontend Developer, tôi chịu trách nhiệm xây dựng các giao diện chính: User, Login, Booking, Blog, Xe, Trạm.\nLộ trình học tập \u0026amp; làm việc 13 tuần: Tuần 1: Quản trị Định danh và Kiến trúc Mạng (08/09 – 12/09)\nThiết lập tài khoản AWS chuẩn doanh nghiệp và xây dựng VPC bảo mật Tuần 2: Điện toán và Lưu trữ Cơ bản (15/09 – 19/09)\nTriển khai EC2, hiểu về các loại lưu trữ (EBS, S3) và Lightsail Tuần 3: Cơ sở dữ liệu và Dịch vụ quản lý (22/09 – 26/09)\nChuyển dịch từ tự quản lý sang Managed Databases (RDS, DynamoDB, ElastiCache) Tuần 4: Khả năng mở rộng, Giám sát và CDN (29/09 – 03/10)\nAuto Scaling, CloudWatch monitoring, Route 53 và CloudFront Tuần 5: Tư duy Vận hành và Hạ tầng dưới dạng Mã (06/10 – 10/10)\nSystems Manager, CloudFormation, AWS CDK Tuần 6: Kiến trúc Bảo mật Đa lớp (13/10 – 17/10)\nWAF, KMS, Secrets Manager, GuardDuty, Cognito Tuần 7: Chiến lược Di chuyển và Khôi phục Thảm họa (20/10 – 24/10)\nVM Import/Export, DMS, SCT, Elastic Disaster Recovery, AWS Backup Tuần 8: Tối ưu hóa Chi phí AWS \u0026amp; Khởi Động Dự Án Voltgo (27/10 – 31/10)\nCost Explorer, Compute Optimizer, Transit Gateway + Bắt đầu dự án Voltgo Frontend Tuần 9: Container AWS \u0026amp; Module Login/User Voltgo (03/11 – 07/11)\nDocker, ECS, EKS + Xây dựng trang Đăng nhập, Đăng ký, Quản lý User Tuần 10: Serverless AWS \u0026amp; Module Xe/Trạm Voltgo (10/11 – 14/11)\nLambda, API Gateway, Step Functions + Xây dựng danh sách Xe, Trạm với Map Tuần 11: Hiện đại hóa Ứng dụng AWS \u0026amp; Module Booking/Blog Voltgo (17/11 – 21/11)\nMicroservices, CI/CD + Xây dựng flow Đặt xe, trang Blog Tuần 12: Data Analytics AWS \u0026amp; Deployment Voltgo (24/11 – 28/11)\nData Lake, Glue, Athena, SageMaker + Testing, CI/CD, Deploy production Tuần 13: Tổng kết \u0026amp; Hoàn thiện Chương trình (01/12 – 07/12)\nAWS Review, Security Audit, Chuẩn bị Certification + Voltgo Final Testing \u0026amp; Bàn giao "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"Tạo một Gateway Endpoint","tags":[],"description":"","content":" Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.1-workshop-overview/","title":"Tổng quan Workshop","tags":[],"description":"","content":"Giới thiệu về EV Rental AI Agent AI Agent là gì? AI Agent là một hệ thống thông minh có thể:\nHiểu các câu hỏi bằng ngôn ngữ tự nhiên Tự động chọn và thực thi các công cụ/chức năng phù hợp Đưa ra quyết định dựa trên ngữ cảnh Cung cấp phản hồi có cấu trúc kèm dữ liệu Khác với chatbot truyền thống có câu trả lời cố định, AI Agent có thể suy luận và hành động một cách linh hoạt.\nKiến trúc hệ thống EV Rental AI Agent sử dụng kiến trúc đa tầng:\n┌─────────────────┐ │ Giao diện │ ← React Frontend (Chat UI) └────────┬────────┘ │ HTTP/REST ↓ ┌─────────────────┐ │ FastAPI Server │ ← Backend điều phối └────────┬────────┘ │ ┌────┴────────────────┐ ↓ ↓ ┌──────────┐ ┌──────────────┐ │ Strands │ │ PostgreSQL │ │ Agent SDK│ │ (Lịch sử) │ └────┬─────┘ └──────────────┘ │ ├─────→ AWS Bedrock (Claude 3.5 Sonnet) ├─────→ Knowledge Base (Chính sách/FAQ) └─────→ Backend API (Xe/Trạm sạc) Các thành phần chính Thành phần Công nghệ Vai trò AI Model AWS Bedrock - Claude 3.5 Sonnet Xử lý ngôn ngữ tự nhiên \u0026amp; sinh phản hồi Agent Framework Strands Agent SDK Tự động chọn tool \u0026amp; điều phối Backend API FastAPI (Python) REST API server cho logic agent Cơ sở dữ liệu PostgreSQL Lưu trữ lịch sử chat \u0026amp; phiên Frontend React + Chakra UI Giao diện chat tương tác Knowledge Base AWS Bedrock KB Truy xuất tài liệu (chính sách, FAQ) Các tính năng chính 1. Tìm kiếm Knowledge Base Agent tìm kiếm trong tài liệu đã upload để trả lời câu hỏi về:\nChính sách thuê xe Thông tin giá cả Quy trình đặt xe Điều khoản và điều kiện Ví dụ câu hỏi:\n\u0026ldquo;Chính sách thuê xe của bạn là gì?\u0026rdquo;\nPhản hồi của Agent:\n## 📋 Chính sách thuê xe VinFast ### 📄 Giấy tờ cần thiết: - ✅ CMND/CCCD còn hiệu lực - ✅ Bằng lái xe (Hạng B1 trở lên) - ✅ Chứng minh nơi cư trú ### 💰 Giá thuê: - **VF8**: 1,500,000 VNĐ/ngày - **VF9**: 2,000,000 VNĐ/ngày - **Đặt cọc**: 10,000,000 VNĐ 2. Tìm kiếm xe Agent truy vấn backend API để tìm xe available dựa trên:\nĐịa điểm (thành phố) Khoảng thời gian Mẫu/loại xe Định dạng phản hồi: Card xe tương tác với thông số kỹ thuật\n3. Tìm trạm sạc Agent lấy thông tin trạm sạc gần đó với:\nĐịa chỉ và trạng thái Số trạm sạc khả dụng Khoảng cách (nếu có vị trí) Định dạng phản hồi: Card trạm sạc với tình trạng thời gian thực\nMục tiêu Workshop Sau khi hoàn thành workshop, bạn sẽ có thể:\n✅ Cấu hình AWS Bedrock - Kích hoạt Claude models và tạo Knowledge Base ✅ Xây dựng Backend AI Agent - Sử dụng Strands SDK để điều phối nhiều tools ✅ Triển khai giao diện Chat - Tạo React chat UI responsive ✅ Kiểm thử End-to-End - Tương tác với AI agent và xác minh tất cả chức năng Công nghệ sử dụng AWS Services:\nAWS Bedrock (Claude 3.5 Sonnet v2) AWS Bedrock Knowledge Bases AWS S3 (lưu trữ tài liệu) IAM (quản lý truy cập) Backend:\nPython 3.11+ FastAPI Strands Agent SDK PostgreSQL SQLAlchemy Frontend:\nReact 18 Chakra UI Axios React Markdown Luồng Workshop Bước 1: Yêu cầu chuẩn bị ↓ Bước 2: Thiết lập AWS Bedrock \u0026amp; Knowledge Base ↓ Bước 3: Triển khai Backend API (FastAPI) ↓ Bước 4: Triển khai Frontend (React) ↓ Bước 5: Kiểm thử AI Agent ↓ Bước 6: Dọn dẹp tài nguyên Tiếp theo: Chuyển sang Yêu cầu chuẩn bị để chuẩn bị môi trường.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Tuần 1: Quản trị Định danh và Kiến trúc Mạng (08/09 – 12/09) Mục tiêu: Thiết lập tài khoản AWS chuẩn doanh nghiệp và xây dựng mạng đám mây ảo (VPC) bảo mật.\nCác công việc đã hoàn thành trong tuần: Ngày Thứ Nội dung Hoạt động chi tiết 08/09 2 Khởi tạo Tài khoản \u0026amp; Quản lý Chi phí - Tạo AWS Account, bảo mật Root User (kích hoạt MFA)\n- Thiết lập AWS Budgets cảnh báo chi phí và sử dụng\n- Nghiên cứu các gói AWS Support (Basic, Developer, Business) 09/09 3 IAM - Phần 1 - Áp dụng nguyên tắc Đặc quyền Tối thiểu (Least Privilege)\n- Tạo IAM Users và Groups (Admins, Developers, Auditors)\n- Cấu hình Account Password Policy theo CIS Benchmark 10/09 4 IAM - Phần 2 - Tạo IAM Roles và Instance Profiles cho EC2\n- Viết custom JSON policies cho quyền truy cập chi tiết\n- Thực hành EC2 truy cập S3 qua Instance Metadata Service 11/09 5 Kiến trúc VPC - Lý thuyết \u0026amp; Thiết kế - Nghiên cứu khái niệm VPC vs Default VPC\n- Quy hoạch không gian địa chỉ IP (CIDR 10.0.0.0/16)\n- Thiết kế mô hình Multi-AZ với Public/Private Subnets 12/09 6 Triển khai VPC - Tạo VPC, Subnets, Internet Gateway\n- Cấu hình Route Tables cho Public/Private subnets\n- Triển khai NAT Gateway cho Private subnet truy cập internet Kết quả đạt được tuần 1: Hiểu các nhóm dịch vụ nền tảng của AWS:\nCompute (Amazon EC2) Networking (Amazon VPC) Identity \u0026amp; Access Management (IAM) Billing \u0026amp; Cost Management (AWS Budgets) Đã tạo và bảo mật thành công tài khoản AWS với MFA trên Root User\nNắm vững các khái niệm IAM:\nTạo Users, Groups với Managed Policies Viết custom JSON policies cho quyền truy cập chi tiết IAM Roles cho EC2 (Instance Profiles) Thiết kế và triển khai VPC chuẩn doanh nghiệp:\nKiến trúc Multi-AZ đảm bảo High Availability Public Subnets cho Load Balancers, Bastion Hosts Private Subnets cho Databases, Application Servers NAT Gateway cho truy cập internet an toàn từ Private subnet Áp dụng tư duy FinOps với AWS Budgets ngay từ ngày đầu\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"📄 Xem Tài liệu Đề xuất Đầy đủ (Google Docs)\nHệ thống cho thuê xe điện tại điểm cố định Phần mềm cho thuê và trả xe điện tại các điểm cố định – Giải pháp di chuyển xanh cho đô thị thông minh 1. Tóm tắt điều hành Hệ thống EV Station-based Rental System được phát triển nhằm cung cấp một nền tảng tất cả trong một cho việc thuê và quản lý xe điện. Hệ thống tích hợp việc đặt xe theo thời gian thực, thanh toán và quản lý điểm thuê thông qua giải pháp đám mây thống nhất. Ứng dụng bao gồm app di động React Native và backend Spring Boot triển khai trên AWS ECS Fargate, với PostgreSQL (RDS) và Redis (ElastiCache) để lưu trữ dữ liệu và tăng tốc độ truy xuất. Xác thực người dùng được quản lý qua Amazon Cognito, trong khi phân phối nội dung toàn cầu được tối ưu bằng CloudFront. Thiết kế theo AWS Well-Architected Framework giúp nền tảng đảm bảo khả năng mở rộng, độ sẵn sàng cao, bảo mật, đồng thời tối ưu chi phí vận hành.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác dịch vụ thuê xe điện hiện nay còn phân mảnh, buộc người dùng phải sử dụng nhiều ứng dụng khác nhau để tìm, đặt và quản lý xe tại các điểm cố định. Điều này gây ra sự bất tiện, hiệu suất chậm và trải nghiệm thiếu tin cậy — người dùng thường đến các điểm thuê “không khả dụng” hoặc “ngoại tuyến”, dẫn đến bức xúc và mất niềm tin.\nĐối với chủ xe và nhà vận hành, việc quản lý đội xe, điều phối đơn thuê và theo dõi bảo trì thủ công gây ra nhiều bất cập, giảm hiệu quả vận hành và mất doanh thu. Hiện chưa có nền tảng thống nhất và thời gian thực kết nối người thuê, chủ xe và nhà vận hành điểm thuê.\nGiải pháp\nHệ thống cho thuê và trả xe điện tại điểm cố định hợp nhất việc thuê và trả xe vào một nền tảng đám mây duy nhất. Hệ thống được xây dựng với React Native cho di động và Spring Boot cho backend, cung cấp tính năng đặt xe theo thời gian thực, theo dõi phương tiện và tích hợp thanh toán.\nCác dịch vụ AWS cốt lõi bao gồm ECS Fargate cho xử lý tính toán, RDS PostgreSQL cho lưu trữ dữ liệu, ElastiCache cho hiệu năng truy xuất nhanh, API Gateway và Cognito cho truy cập bảo mật, và CloudFront cho phân phối nội dung toàn cầu. Nền tảng hỗ trợ cả hình thức quản lý đội xe và chia sẻ xe P2P, cung cấp giao diện tập trung cho người dùng và nhà vận hành để quản lý việc thuê xe hiệu quả, an toàn và dễ mở rộng.\nLợi ích và hoàn vốn đầu tư (ROI)\nNền tảng loại bỏ sự phân mảnh ứng dụng và thao tác thủ công, mang lại trải nghiệm thống nhất, tự động cho cả người thuê và chủ xe. Dữ liệu thời gian thực đảm bảo độ tin cậy và minh bạch về tình trạng xe và điểm thuê.\nThiết kế theo AWS Well-Architected Framework giúp tối ưu chi phí vận hành thông qua mô hình serverless, trả theo mức sử dụng, đồng thời duy trì khả năng mở rộng và độ sẵn sàng 99,99%. Trong vòng 12–24 tháng, nền tảng dự kiến đạt 50.000+ người dùng hoạt động hàng tháng, hợp tác với 200+ điểm thuê, và mang lại hiệu quả đáng kể về thời gian, chi phí và vận hành cho cả người dùng và nhà vận hành.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nDịch vụ AWS sử dụng\nAWS IoT Core: Tiếp nhận dữ liệu MQTT từ 5 trạm, mở rộng lên 15. AWS Lambda: Xử lý dữ liệu và kích hoạt Glue jobs (2 hàm). Amazon API Gateway: Giao tiếp với ứng dụng web. Amazon S3: Lưu trữ dữ liệu thô (data lake) và dữ liệu đã xử lý (2 bucket). AWS Glue: Crawlers lập chỉ mục dữ liệu, ETL jobs chuyển đổi và tải dữ liệu. AWS Amplify: Lưu trữ giao diện web Next.js. Amazon Cognito: Quản lý quyền truy cập cho người dùng phòng lab. Thiết kế thành phần\nThiết bị biên: Raspberry Pi thu thập và lọc dữ liệu cảm biến, gửi tới IoT Core. Tiếp nhận dữ liệu: AWS IoT Core nhận tin nhắn MQTT từ thiết bị biên. Lưu trữ dữ liệu: Dữ liệu thô lưu trong S3 data lake; dữ liệu đã xử lý lưu ở một S3 bucket khác. Xử lý dữ liệu: AWS Glue Crawlers lập chỉ mục dữ liệu; ETL jobs chuyển đổi để phân tích. Giao diện web: AWS Amplify lưu trữ ứng dụng Next.js cho bảng điều khiển và phân tích thời gian thực. Quản lý người dùng: Amazon Cognito giới hạn 5 tài khoản hoạt động. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần — thiết lập trạm thời tiết biên và xây dựng nền tảng thời tiết — mỗi phần trải qua 4 giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu Raspberry Pi với cảm biến ESP32 và thiết kế kiến trúc AWS Serverless (1 tháng trước kỳ thực tập). Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính và điều chỉnh (Tháng 1). Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tinh chỉnh (ví dụ tối ưu Lambda với Next.js) để đảm bảo hiệu quả (Tháng 2). Phát triển, kiểm thử, triển khai: Lập trình Raspberry Pi, AWS services với CDK/SDK và ứng dụng Next.js, sau đó kiểm thử và đưa vào vận hành (Tháng 2–3). Yêu cầu kỹ thuật\nTrạm thời tiết biên: Cảm biến (nhiệt độ, độ ẩm, lượng mưa, tốc độ gió), vi điều khiển ESP32, Raspberry Pi làm thiết bị biên. Raspberry Pi chạy Raspbian, sử dụng Docker để lọc dữ liệu và gửi 1 MB/ngày/trạm qua MQTT qua Wi-Fi. Nền tảng thời tiết: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), Lambda (giảm thiểu do Next.js xử lý), AWS Glue (ETL), S3 (2 bucket), IoT Core (gateway và rules), và Cognito (5 người dùng). Sử dụng AWS CDK/SDK để lập trình (ví dụ IoT Core rules tới S3). Next.js giúp giảm tải Lambda cho ứng dụng web fullstack. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp phần cứng. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Lambda: 0,00 USD/tháng (1.000 request, 512 MB lưu trữ). S3 Standard: 0,15 USD/tháng (6 GB, 2.100 request, 1 GB quét). Truyền dữ liệu: 0,02 USD/tháng (1 GB vào, 1 GB ra). AWS Amplify: 0,35 USD/tháng (256 MB, request 500 ms). Amazon API Gateway: 0,01 USD/tháng (2.000 request). AWS Glue ETL Jobs: 0,02 USD/tháng (2 DPU). AWS Glue Crawlers: 0,07 USD/tháng (1 crawler). MQTT (IoT Core): 0,08 USD/tháng (5 thiết bị, 45.000 tin nhắn). Tổng: 0,7 USD/tháng, 8,40 USD/12 tháng\nPhần cứng: 265 USD một lần (Raspberry Pi 5 và cảm biến). 7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng trung bình, xác suất trung bình. Hỏng cảm biến: Ảnh hưởng cao, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nMạng: Lưu trữ cục bộ trên Raspberry Pi với Docker. Cảm biến: Kiểm tra định kỳ, dự phòng linh kiện. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 trạm.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.2-prerequiste/","title":"Điều kiện tiên quyết","tags":[],"description":"","content":"Điều kiện tiên quyết cho Workshop EV Rental AI Agent Trước khi bắt đầu workshop này, hãy đảm bảo bạn đã chuẩn bị các yêu cầu sau:\n1. Tài khoản AWS Bạn cần một Tài khoản AWS với quyền phù hợp để:\nTruy cập dịch vụ AWS Bedrock Tạo và quản lý IAM users Tạo S3 buckets (cho Knowledge Base) Tạo Knowledge Bases Lưu ý: Bedrock chỉ khả dụng ở một số vùng cụ thể. Các vùng được khuyến nghị:\nus-west-2 (Oregon) us-east-1 (N. Virginia) ap-southeast-1 (Singapore) 2. IAM User với Quyền Bedrock Bạn cần tạo IAM User với quyền truy cập AWS Bedrock cho ứng dụng.\nBước 1: Tạo IAM User\nVào AWS Console → IAM → Users → Create User Tên user: bedrock-agent-user ✅ Chọn: Provide user access to the AWS Management Console (tùy chọn) ✅ Chọn: I want to create an IAM user Click Next Bước 2: Gán Quyền\nChọn: Attach policies directly Tìm và chọn các policies sau: ✅ AmazonBedrockFullAccess - Quyền truy cập đầy đủ Bedrock models và Knowledge Bases ✅ (Tùy chọn) AmazonS3ReadOnlyAccess - Nếu sử dụng Knowledge Base với S3 Click Next → Create User Bước 3: Tạo Access Keys\nClick vào user vừa tạo: bedrock-agent-user Vào tab Security credentials Cuộn xuống Access keys → Click Create access key ⚠️ QUAN TRỌNG: Copy và lưu lại: Access Key ID (ví dụ: AKIAIOSFODNN7EXAMPLE) Secret Access Key (chỉ hiển thị 1 lần, ví dụ: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY) Click Done ⚠️ Lưu ý Bảo mật:\n# Lưu vào file .env (KHÔNG commit lên Git) AWS_ACCESS_KEY_ID=YOUR_ACCESS_KEY_ID_HERE AWS_SECRET_ACCESS_KEY=YOUR_SECRET_ACCESS_KEY_HERE AWS_REGION=us-west-2 3. Môi trường Phát triển 3.1. Môi trường Python Python 3.11 hoặc cao hơn Trình quản lý package: pip Kiểm tra cài đặt:\npython --version # Mong đợi: Python 3.11.x hoặc cao hơn pip --version 3.2. Môi trường Node.js Node.js 18+ và npm Yêu cầu cho React frontend Kiểm tra cài đặt:\nnode --version # Mong đợi: v18.x.x hoặc cao hơn npm --version 3.3. Cơ sở dữ liệu PostgreSQL PostgreSQL 14+ cài đặt local hoặc sử dụng Docker Tùy chọn 1: Cài đặt local\nTải từ: https://www.postgresql.org/download/ Tạo database: ev_rental_db Tùy chọn 2: Sử dụng Docker\ndocker run -d \\ --name postgres-ev \\ -e POSTGRES_PASSWORD=password \\ -e POSTGRES_DB=ev_rental_db \\ -p 5432:5432 \\ postgres:14 Kiểm tra PostgreSQL:\n# Kiểm tra PostgreSQL đang chạy psql --version # Kết nối database psql -U postgres -d ev_rental_db 4. Code Editor \u0026amp; Công cụ VS Code hoặc IDE bạn ưa thích Git để clone repositories Postman hoặc cURL để test API (tùy chọn) Cài đặt VS Code:\nTải từ: https://code.visualstudio.com/ Cài đặt Git:\n# macOS brew install git # Windows # Tải từ: https://git-scm.com/download/win # Kiểm tra git --version 5. AWS CLI (Tùy chọn) Cài đặt AWS CLI để tương tác với các dịch vụ AWS từ command line:\n# macOS/Linux curl \u0026#34;https://awscli.amazonaws.com/AWSCLIV2.pkg\u0026#34; -o \u0026#34;AWSCLIV2.pkg\u0026#34; sudo installer -pkg AWSCLIV2.pkg -target / # Windows # Tải từ: https://awscli.amazonaws.com/AWSCLIV2.msi # Kiểm tra aws --version Cấu hình AWS CLI:\naws configure # Nhập Access Key ID: AKIA5GPEMGJZK6E7PMEB # Nhập Secret Access Key: (dán secret key của bạn) # Default region name: us-west-2 # Default output format: json Test AWS CLI:\n# Liệt kê các Bedrock models có sẵn aws bedrock list-foundation-models --region us-west-2 # Kiểm tra identity của bạn aws sts get-caller-identity Danh sách Kiểm tra Trước khi tiếp tục bước tiếp theo, đảm bảo bạn có:\n✅ Tài khoản AWS với quyền truy cập Bedrock ở vùng được hỗ trợ ✅ IAM User đã tạo với policy AmazonBedrockFullAccess ✅ Access Key ID và Secret Access Key đã lưu an toàn ✅ Python 3.11+ đã cài đặt và kiểm tra ✅ Node.js 18+ và npm đã cài đặt và kiểm tra ✅ PostgreSQL 14+ database đang chạy ✅ Code editor (VS Code khuyến nghị) đã cài đặt ✅ Git đã cài đặt và cấu hình ✅ (Tùy chọn) AWS CLI đã cài đặt và cấu hình Chi phí Ước tính Workshop này sử dụng các dịch vụ AWS sau:\nDịch vụ Chi phí Ước tính Ghi chú AWS Bedrock - Claude 3.5 Sonnet ~$0.50 - $2.00 Tính theo API call (input/output tokens) AWS Bedrock - Knowledge Base ~$0.10 - $0.50 Vector storage + retrieval S3 Storage ~$0.02 Tối thiểu cho documents Data Transfer ~$0.05 Thường trong free tier Tổng ~$0.67 - $2.57 Cho toàn bộ workshop 💡 Lưu ý: Nhớ dọn dẹp tài nguyên sau workshop để tránh phí phát sinh!\nTiếp theo: Chuyển sang Thiết lập AWS Bedrock để enable models và tạo Knowledge Base.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;AWS Cloud Mastery Series #1: GENERATIVE AI, RAG \u0026amp; AWS AGENTIC AI\u0026rdquo; I. TỔNG QUAN SỰ KIỆN Tên sự kiện: AWS Cloud Mastery Series #1: GENERATIVE AI, RAG \u0026amp; AWS AGENTIC AI\nMục tiêu tham dự:\nNắm bắt kỹ thuật Prompt Engineering và các dịch vụ AI có sẵn trên AWS Tìm hiểu sâu về RAG (Retrieval-Augmented Generation) và ứng dụng trong doanh nghiệp Cập nhật xu hướng Agentic AI và giải pháp đưa AI Agent từ thử nghiệm (POC) sang thực tế (Production) Khám phá công nghệ Voice AI thời gian thực với Pipecat Danh Sách Diễn Giả:\nLâm Tuấn Kiệt - Sr DevOps Engineer (FPT Software) Danh Hoàng Hiếu Nghị - AI Engineer (Renova Cloud) Đinh Lê Hoàng Anh - Cloud Engineer Trainee (First Cloud AI Journey) II. NỘI DUNG KIẾN THỨC TRỌNG TÂM Qua phần trình bày của các diễn giả từ FPT Software, Renova Cloud và First Cloud AI Journey, tôi đã tổng hợp được các nhóm kiến thức cốt lõi sau:\n1. Prompt Engineering \u0026amp; Foundation Models (Nền tảng cốt lõi) Tôi đã củng cố được tư duy về cách giao tiếp với các Mô hình Nền tảng (Foundation Models) trên Amazon Bedrock. Điểm nhấn là sự khác biệt hiệu quả giữa:\nZero-shot / Few-shot Prompting: Kỹ thuật điều hướng mô hình bằng chỉ dẫn trực tiếp hoặc cung cấp ví dụ mẫu Chain of Thought (CoT): Kỹ thuật yêu cầu mô hình \u0026ldquo;suy luận từng bước\u0026rdquo;, giúp tăng đáng kể độ chính xác khi xử lý các vấn đề logic phức tạp 2. Các Dịch vụ AWS AI Tiền huấn luyện (Pretrained Services) Sự kiện đã hệ thống hóa lại các API \u0026ldquo;Ready-to-use\u0026rdquo; giúp tích hợp trí tuệ nhân tạo mà không cần huấn luyện mô hình lại từ đầu:\nHình ảnh/Video: Amazon Rekognition Ngôn ngữ \u0026amp; Văn bản: Amazon Translate, Comprehend, Textract (OCR) Âm thanh: Amazon Polly (Text-to-Speech) và Transcribe (Speech-to-Text) 3. RAG - Retrieval Augmented Generation Đây là giải pháp quan trọng để giải quyết vấn đề \u0026ldquo;ảo giác\u0026rdquo; (hallucinations) của AI khi áp dụng vào doanh nghiệp. Quy trình được làm rõ thông qua:\nSử dụng Amazon Titan Text Embeddings V2 để vector hóa dữ liệu phục vụ tìm kiếm ngữ nghĩa Tận dụng Knowledge Bases for Amazon Bedrock để quản lý toàn trình từ khâu Chunking (chia nhỏ), lưu trữ Vector, đến Truy xuất và Tạo sinh câu trả lời 4. Sự chuyển dịch sang Agentic AI \u0026amp; Thách thức Production Tôi đã nắm bắt được sự tiến hóa từ GenAI Assistants (làm theo quy tắc) sang GenAI Agents (hướng mục tiêu, tự chủ). Tuy nhiên, việc chuyển đổi từ POC sang Production gặp rào cản lớn về:\nHiệu suất và Khả năng mở rộng Bảo mật, Quản trị và Kiểm soát truy cập Sự phức tạp trong quản lý bộ nhớ và ngữ cảnh 5. Giải pháp Amazon Bedrock AgentCore Để giải quyết các thách thức trên, AWS giới thiệu AgentCore với các thành phần:\nRuntime \u0026amp; Memory: Môi trường thực thi và khả năng ghi nhớ lịch sử tương tác Identity \u0026amp; Gateway: Quản lý định danh và bảo mật Code Interpreter: Cho phép Agent viết và chạy code để xử lý dữ liệu phức tạp Observability: Công cụ giám sát và kiểm toán hành vi của Agent 6. Pipecat Framework (Voice AI) Một framework mã nguồn mở ấn tượng dành cho trợ lý ảo đa phương thức, hoạt động theo cơ chế pipeline thời gian thực: $WebRTC \\rightarrow STT \\rightarrow LLM \\rightarrow TTS \\rightarrow Output$.\nIII. ĐÁNH GIÁ \u0026amp; BÀI HỌC KINH NGHIỆM Sau khi tham gia workshop, tôi rút ra được 3 bài học và thay đổi trong tư duy quan trọng:\n1. Tư duy chuyển dịch từ \u0026ldquo;Hỏi - Đáp\u0026rdquo; sang \u0026ldquo;Hành động\u0026rdquo; (Agentic AI) Trước đây, tôi thường giới hạn AI ở việc trò chuyện hoặc tóm tắt. Tuy nhiên, khái niệm Agentic AI đã mở ra viễn cảnh về những \u0026ldquo;nhân viên ảo\u0026rdquo; thực thụ. Khả năng lập kế hoạch và sử dụng công cụ (tool-use) của Agent là bước tiến lớn giúp tự động hóa các quy trình phức tạp mà không cần sự can thiệp liên tục của con người.\n2. Giải bài toán \u0026ldquo;Production\u0026rdquo; với AgentCore Tôi rất tâm đắc với phần thảo luận về \u0026ldquo;Hố sâu ngăn cách\u0026rdquo; giữa POC và Production. Việc sử dụng các công cụ như Amazon Bedrock AgentCore không chỉ là vấn đề kỹ thuật mà là chìa khóa để xây dựng niềm tin doanh nghiệp. Các lớp bảo mật và kiểm soát (Observability) là yếu tố bắt buộc để doanh nghiệp dám giao việc cho AI.\n3. Tiềm năng ứng dụng thực tế của Pipecat Sự kết hợp giữa WebRTC và AI Model của Pipecat tạo ra trải nghiệm hội thoại độ trễ cực thấp. Điều này gợi mở cho tôi nhiều ý tưởng ứng dụng thực tế như: tổng đài chăm sóc khách hàng thông minh, trợ lý phỏng vấn tuyển dụng, hoặc các ứng dụng luyện ngoại ngữ thời gian thực.\nIV. KẾT LUẬN Workshop \u0026ldquo;Generative AI \u0026amp; Agentic AI on AWS\u0026rdquo; đã mang lại cái nhìn toàn cảnh và lộ trình công nghệ rõ ràng:\nHiện tại: Tập trung làm chủ RAG và Prompt Engineering Tương lai: Hướng tới kỷ nguyên Agentic AI và các Tác tử tự chủ Công cụ: Tận dụng hệ sinh thái AWS (Bedrock, AgentCore) và các Framework như Pipecat để hiện thực hóa các ý tưởng đột phá Workshop không chỉ cung cấp kiến thức lý thuyết mà còn trang bị cho tôi tầm nhìn thực tế về việc triển khai các giải pháp AI trong môi trường doanh nghiệp, đặc biệt là sự chuyển đổi từ các dự án thử nghiệm sang hệ thống sản xuất có tính bền vững và đáng tin cậy.\nMột số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của bạn tại đây Tổng thể, sự kiện đã giúp tôi mở rộng hiểu biết về xu hướng Generative AI và Agentic AI, đồng thời cung cấp công cụ và phương pháp luận cụ thể để áp dụng vào thực tế.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"Kiểm tra Gateway Endpoint","tags":[],"description":"","content":"Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"Tạo một S3 Interface endpoint","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Tuần 2: Điện toán và Lưu trữ Cơ bản (15/09 – 19/09) Mục tiêu: Triển khai máy chủ ảo (EC2), hiểu về các loại hình lưu trữ (EBS, S3) và các mô hình điện toán đơn giản hóa (Lightsail).\nCác công việc đã hoàn thành trong tuần: Ngày Thứ Nội dung Hoạt động chi tiết 15/09 2 Amazon EC2 - Khởi tạo \u0026amp; Kết nối - Phân tích các loại instance: T3 (Burstable), C5 (Compute), R5 (Memory)\n- Khởi tạo Amazon Linux 2023 instance\n- Kết nối SSH với Key Pairs (.pem/.ppk) 16/09 3 Lưu trữ EBS \u0026amp; Windows Workloads - Tạo và mount EBS volume gp3 vào Linux instance\n- Triển khai Windows Server 2022, kết nối qua RDP\n- Tạo EBS Snapshots để sao lưu 17/09 4 Môi trường Phát triển Cloud9 - Thiết lập IDE trên trình duyệt với AWS CLI, SAM, Docker cài sẵn\n- Truy cập từ xa không cần mở port SSH\n- Trải nghiệm code và terminal trực tiếp từ browser 18/09 5 Amazon S3 Cơ bản - Tạo S3 Bucket và upload file media\n- Cấu hình Static Website Hosting\n- Viết Bucket Policy JSON cho public GetObject access 19/09 6 S3 Nâng cao \u0026amp; Bảo mật - Phân tích Storage Classes: Standard, Intelligent-Tiering, Glacier\n- Thiết lập Lifecycle Policy chuyển object cũ sang Glacier\n- Bật Block Public Access, Versioning, Default Encryption (SSE-S3) Kết quả đạt được tuần 2: Thành thạo EC2:\nHiểu các họ instance và trường hợp sử dụng Khởi tạo và kết nối thành công cả Linux và Windows instances Tạo EBS volumes và snapshots cho data persistence Cloud Development:\nThiết lập Cloud9 IDE loại bỏ vấn đề môi trường local Trải nghiệm truy cập được quản lý không cần SSH public ports Object Storage:\nTriển khai S3 static website với access policies phù hợp Áp dụng tối ưu chi phí với Lifecycle Policies Áp dụng best practices bảo mật: Block Public Access, Versioning, Encryption Khái niệm quan trọng:\nEBS là lưu trữ bền vững độc lập với vòng đời EC2 S3 cung cấp object storage có khả năng mở rộng không giới hạn Cơ chế incremental backup với Snapshots "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;AWS Cloud Mastery Series #2: From DevOps, IaC to Containers \u0026amp; Observability\u0026rdquo; I. TỔNG QUAN SỰ KIỆN Tên sự kiện: AWS Cloud Mastery Series #2: From DevOps, IaC to Containers \u0026amp; Observability\nMục tiêu tham dự:\nChuẩn hóa tư duy (Mindset): Hiểu sâu về Chu trình giá trị (Value Cycle) và vai trò cốt lõi của DevOps Hiện đại hóa hạ tầng (IaC): Chuyển dịch từ thao tác thủ công (ClickOps) sang quản lý hạ tầng bằng mã (Infrastructure as Code) Tối ưu hóa ứng dụng (Containerization): Nắm vững chiến lược lựa chọn nền tảng container phù hợp (App Runner, ECS, EKS) Giám sát toàn diện (Observability): Xây dựng hệ thống giám sát chủ động với CloudWatch và X-Ray Danh Sách Diễn Giả:\nĐội ngũ chuyên gia AWS \u0026amp; Cloud Engineers: Chia sẻ về kiến trúc hệ thống, chiến lược Platform Engineering và demo kỹ thuật chuyên sâu.\nII. NỘI DUNG KIẾN THỨC TRỌNG TÂM Dưới sự chia sẻ của các chuyên gia AWS và kỹ sư Cloud, tôi đã đúc kết được các khối kiến thức nền tảng sau:\n1. Tư duy DevOps \u0026amp; CI/CD Pipeline Sự kiện bắt đầu bằng việc định nghĩa lại DevOps không chỉ là công cụ, mà là văn hóa tối ưu hóa dòng chảy giá trị.\nChu trình giá trị (Value Cycle): Quy trình khép kín 5 bước nhằm tăng tốc độ giao hàng (Speed) nhưng vẫn đảm bảo sự ổn định (Stability).\nChiến lược Pipeline hiệu quả:\nPhân biệt rõ Concepts:\nContinuous Integration (CI): Fail fast, tích hợp code hàng ngày Continuous Delivery: Tự động đến Staging, cần con người duyệt để lên Production Continuous Deployment: Tự động hóa 100% đến Production Nguyên tắc \u0026ldquo;Build Once, Deploy Anywhere\u0026rdquo;: Source code chỉ được build một lần duy nhất thành gói Binary (Artifact). Các môi trường sau (Staging, Prod) sử dụng lại chính Artifact này để đảm bảo tính nhất quán tuyệt đối.\nĐiều kiện Fail Fast: Pipeline phải dừng ngay lập tức khi gặp lỗi biên dịch, vi phạm Code Style, lỗ hổng bảo mật hoặc test quá chậm.\n2. Infrastructure as Code (IaC) - Từ ClickOps đến Code Phần này giải quyết bài toán loại bỏ thói quen thao tác tay (\u0026ldquo;ClickOps\u0026rdquo;) dễ gây lỗi và khó mở rộng. Tôi đã phân tích sâu 3 công cụ chủ đạo:\nAWS CloudFormation (Native):\nSử dụng YAML/JSON Quản lý tài nguyên theo đơn vị Stack Xóa Stack đồng nghĩa xóa toàn bộ tài nguyên liên quan Terraform (Multi-Cloud):\nSử dụng ngôn ngữ HCL Điểm mạnh là hỗ trợ đa nền tảng Quy trình làm việc an toàn: $Code \\rightarrow Plan \\text{ (Review thay đổi)} \\rightarrow Apply$ AWS CDK (Cloud Development Kit):\nCho phép định nghĩa hạ tầng bằng ngôn ngữ lập trình (Python, TypeScript\u0026hellip;) Constructs: Từ L1 (Cấu hình chi tiết) đến L3 (Patterns kiến trúc phức tạp) Drift Detection: Tính năng quan trọng giúp phát hiện sự sai lệch giữa Code và Thực tế (do ai đó sửa tay trên Console) 3. Chiến lược Containerization Việc lựa chọn nền tảng chạy Container phụ thuộc vào quy mô và nhu cầu:\nAmazon ECS: Đơn giản, tích hợp sâu với AWS, phù hợp cho team muốn vận hành nhanh gọn Amazon EKS: Dựa trên Kubernetes chuẩn, hệ sinh thái lớn, phù hợp cho Enterprise hoặc hệ thống phức tạp/Hybrid AWS App Runner: Giải pháp \u0026ldquo;Zero-ops\u0026rdquo; cho Web App/API, tự động từ Source/Image ra URL HTTPS mà không cần cấu hình server Mô hình tính toán (Compute Options):\nEC2 Launch Type: Kiểm soát cao nhất nhưng tốn công vận hành (patching, scaling) AWS Fargate (Serverless): AWS lo hạ tầng, người dùng chỉ cần định nghĩa CPU/RAM cho Task 4. Observability - Giám sát \u0026amp; Tối ưu Khép kín vòng đời phát triển bằng khả năng quan sát sâu:\nAmazon CloudWatch: \u0026ldquo;Mắt và Tai\u0026rdquo; của hệ thống (Metrics, Logs, Alarms) AWS X-Ray: Giải quyết bài toán \u0026ldquo;mò kim đáy bể\u0026rdquo; trong Microservices bằng Distributed Tracing (theo vết request đi qua nhiều service để tìm điểm nghẽn) III. ĐÁNH GIÁ \u0026amp; BÀI HỌC KINH NGHIỆM Tham gia chuỗi workshop này đã thay đổi đáng kể nhận thức và kỹ năng của tôi:\n1. Sự chuyển dịch từ \u0026ldquo;Ops\u0026rdquo; sang \u0026ldquo;Platform Engineering\u0026rdquo; Tôi nhận ra vai trò của DevOps hiện đại không phải là chạy theo Developer để deploy code thủ công. DevOps là người kiến tạo nên \u0026ldquo;Đường cao tốc\u0026rdquo; (Pipeline \u0026amp; Platform). Một Platform tốt cho phép Developer có khả năng Self-service (tự phục vụ) việc tạo môi trường và deploy code nhanh chóng nhưng vẫn nằm trong hành lang an toàn (Governance) mà team DevOps thiết lập.\n2. Kỷ luật trong vận hành (Operational Discipline) Bài học về Artifact Management và Drift Detection là những quy tắc vàng. Trong môi trường Enterprise, sự nhất quán là sống còn. Việc build khác nhau ở các môi trường hay sửa tay (manual changes) vào hệ thống đang quản lý bằng code cần phải bị nghiêm cấm.\n3. Chiến lược chọn công cụ thông minh Không có công cụ \u0026ldquo;tốt nhất\u0026rdquo;, chỉ có công cụ \u0026ldquo;phù hợp nhất\u0026rdquo;:\nCần sự ổn định tuyệt đối và hỗ trợ sâu nhất dịch vụ mới của AWS $\\rightarrow$ Chọn CloudFormation Doanh nghiệp dùng Multi-cloud hoặc Hybrid-cloud $\\rightarrow$ Terraform là tối ưu Team Developer mạnh về lập trình, cần dựng kiến trúc phức tạp nhanh và tái sử dụng code $\\rightarrow$ AWS CDK Web App đơn giản $\\rightarrow$ Dùng App Runner thay vì tốn nguồn lực vận hành cụm Kubernetes IV. KẾT LUẬN Series \u0026ldquo;DevOps \u0026amp; IaC Mastery\u0026rdquo; đã cung cấp một lộ trình hoàn chỉnh cho hành trình Cloud:\nTư duy: Chuyển từ làm thủ công sang tự động hóa và đo lường bằng số liệu Hạ tầng: Làm chủ IaC để có hệ thống mở rộng, tái tạo được và kiểm soát sai lệch (Drift) Vận hành: Kết hợp Containerization linh hoạt và Observability sâu sát để đảm bảo hệ thống ổn định, hiệu năng cao Đây là nền tảng kiến thức vững chắc để tôi tự tin xây dựng và vận hành các hệ thống phần mềm quy mô lớn trên AWS.\nMột số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của bạn tại đây Tổng thể, workshop đã giúp tôi có cái nhìn toàn diện về DevOps hiện đại, từ mindset, công cụ IaC, chiến lược containerization đến observability, tạo nền tảng vững chắc cho việc xây dựng và vận hành hệ thống Cloud-native.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"Kiểm tra Interface Endpoint","tags":[],"description":"","content":"Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.3-setup-bedrock/","title":"Thiết lập AWS Bedrock","tags":[],"description":"","content":"Thiết lập AWS Bedrock \u0026amp; Knowledge Base Trong phần này, bạn sẽ cấu hình AWS Bedrock để sử dụng Claude 3.5 Sonnet và tạo Knowledge Base cho việc truy xuất tài liệu.\nBước 1: Kích hoạt Model Access QUAN TRỌNG: Bạn phải kích hoạt quyền truy cập model trước khi sử dụng Bedrock, nếu không sẽ gặp lỗi ValidationException.\nVào AWS Console → Services → Bedrock Ở thanh sidebar bên trái, click Model access (trong mục Foundation models) Click nút Manage model access (màu cam) Tìm và chọn các models sau: ✅ Anthropic - Claude 3.5 Sonnet v2 (anthropic.claude-3-5-sonnet-20241022-v2:0) ✅ Amazon - Titan Embeddings G1 - Text (cho Knowledge Base) Click Request model access (góc dưới bên phải) Đợi phê duyệt: Instant access models: Có sẵn ngay lập tức (màu xanh ✅) Models khác: Đợi 5-30 phút (trạng thái đổi từ \u0026ldquo;In progress\u0026rdquo; → \u0026ldquo;Access granted\u0026rdquo;) Kiểm tra models đã được kích hoạt:\n# Sử dụng AWS CLI aws bedrock list-foundation-models --region us-west-2 # Hoặc kiểm tra trong Console: # Bedrock → Model access → Status phải là \u0026#34;Access granted\u0026#34; Bước 2: Tạo S3 Bucket cho Knowledge Base Knowledge Base yêu cầu S3 bucket để lưu trữ tài liệu.\nVào S3 → Create bucket Tên bucket: ev-rental-knowledge-docs (phải là tên duy nhất toàn cầu) Region: Giống với region Bedrock của bạn (ví dụ: us-west-2) Block all public access: ✅ Bật (khuyến nghị) Click Create bucket Bước 3: Upload tài liệu lên S3 Upload các tài liệu chính sách thuê xe (PDF, TXT, DOCX):\nCác tài liệu mẫu cần upload:\nrental-policy.pdf - Chính sách và điều khoản thuê xe pricing.pdf - Thông tin giá xe faq.txt - Câu hỏi thường gặp booking-process.pdf - Cách đặt xe Upload qua Console:\nVào S3 bucket của bạn: ev-rental-knowledge-docs Click Upload → Add files Chọn các tài liệu Click Upload Upload qua AWS CLI:\naws s3 cp rental-policy.pdf s3://ev-rental-knowledge-docs/ aws s3 cp pricing.pdf s3://ev-rental-knowledge-docs/ aws s3 cp faq.txt s3://ev-rental-knowledge-docs/ aws s3 cp booking-process.pdf s3://ev-rental-knowledge-docs/ Bước 4: Tạo Knowledge Base Vào Bedrock → Knowledge Bases → Create Knowledge base name: ev-rental-knowledge-base Description: \u0026ldquo;Chính sách và FAQ cho thuê xe điện VinFast\u0026rdquo; Click Next Cấu hình Data source:\nData source name: rental-docs S3 URI: s3://ev-rental-knowledge-docs/ Click Next Embeddings model:\nChọn: Titan Embeddings G1 - Text (amazon.titan-embed-text-v1) Vector database: Chọn Bedrock managed (OpenSearch Serverless) (tùy chọn dễ nhất) Click Next Review và tạo:\nXem lại tất cả cài đặt Click Create knowledge base Đợi quá trình tạo hoàn tất (2-3 phút) Bước 5: Sync Data Source Sau khi Knowledge Base được tạo, bạn cần đồng bộ dữ liệu:\nTrong Knowledge Base, vào tab Data sources Chọn data source của bạn: rental-docs Click nút Sync Đợi sync hoàn tất (kiểm tra trạng thái: \u0026ldquo;Syncing\u0026rdquo; → \u0026ldquo;Ready\u0026rdquo;) Quá trình này sẽ lập chỉ mục tất cả tài liệu và tạo vector embeddings Trạng thái Sync:\n🔄 Syncing: Đang xử lý ✅ Ready: Hoàn thành thành công ❌ Failed: Kiểm tra quyền S3 hoặc định dạng tài liệu Bước 6: Lấy Knowledge Base ID Bạn sẽ cần ID này cho ứng dụng backend:\nTrong trang Knowledge Base Copy Knowledge Base ID (định dạng: 89CI1JSSE4 hoặc tương tự) Lưu vào ghi chú - bạn sẽ sử dụng nó ở bước tiếp theo Ví dụ Knowledge Base ID:\nKnowledge Base ID: 89CI1JSSE4 Knowledge Base ARN: arn:aws:bedrock:us-west-2:123456789:knowledge-base/89CI1JSSE4 Bước 7: Test Knowledge Base (Tùy chọn) Test Knowledge Base trực tiếp trong console:\nVào Knowledge Base của bạn Click tab Test Nhập câu hỏi: \u0026ldquo;Chính sách thuê xe là gì?\u0026rdquo; Click Run Xác minh nó trả về thông tin liên quan từ tài liệu Checklist xác minh Trước khi chuyển sang bước tiếp theo, đảm bảo:\n✅ Quyền truy cập Claude 3.5 Sonnet v2 đã được cấp ✅ Quyền truy cập Titan Embeddings đã được cấp ✅ S3 bucket đã tạo và upload tài liệu ✅ Knowledge Base đã tạo và sync thành công ✅ Knowledge Base ID đã lưu ✅ Câu hỏi test trả về kết quả liên quan Xử lý sự cố Vấn đề: \u0026ldquo;ValidationException: Model not enabled\u0026rdquo;\nGiải pháp: Vào Bedrock → Model access và kích hoạt model Vấn đề: \u0026ldquo;Sync failed\u0026rdquo;\nKiểm tra quyền truy cập S3 bucket Xác minh định dạng tài liệu (hỗ trợ PDF, TXT, DOCX) Kiểm tra CloudWatch Logs để xem lỗi chi tiết Vấn đề: \u0026ldquo;Không có kết quả từ Knowledge Base\u0026rdquo;\nĐảm bảo tài liệu đã upload lên S3 Chạy sync lại Đợi vài phút sau khi sync hoàn tất Thử đặt câu hỏi theo cách khác Tiếp theo: Chuyển sang Deploy Backend API để xây dựng FastAPI server.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.3-s3-vpc/","title":"Truy cập S3 từ VPC","tags":[],"description":"","content":"Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Tuần 3: Cơ sở dữ liệu và Dịch vụ quản lý (22/09 – 26/09) Mục tiêu: Chuyển dịch từ việc tự quản lý cơ sở dữ liệu trên EC2 sang sử dụng các dịch vụ Managed Database (RDS, DynamoDB) để giảm tải vận hành.\nCác công việc đã hoàn thành trong tuần: Ngày Thứ Nội dung Hoạt động chi tiết 22/09 2 Triển khai Amazon RDS - Deploy RDS với MySQL/PostgreSQL engine\n- Kích hoạt Multi-AZ cho high availability\n- Phân tích Synchronous Replication và cơ chế automatic failover 23/09 3 Kết nối \u0026amp; Vận hành RDS - Cấu hình Security Group chỉ cho phép App-Tier truy cập\n- Tùy chỉnh cấu hình DB qua Parameter Groups\n- Thực hành Automated Backups và Manual Snapshots 24/09 4 Amazon DynamoDB - Phần 1 - Tạo bảng DynamoDB với Partition Key\n- Hiểu sự khác biệt schema SQL vs NoSQL\n- So sánh Provisioned vs On-Demand capacity modes 25/09 5 DynamoDB Nâng cao - Phần 2 - Thực hành các API: PutItem, GetItem, Query, Scan\n- Hiểu hiệu quả Query vs Scan\n- Tạo Global Secondary Index (GSI) cho truy vấn thay thế 26/09 6 Amazon ElastiCache - Triển khai ElastiCache với Redis engine\n- Áp dụng chiến lược caching Lazy Loading\n- Đặt cache cluster trong Private Subnet để bảo mật Kết quả đạt được tuần 3: Cơ sở dữ liệu Quan hệ:\nTriển khai RDS với Multi-AZ đảm bảo high availability Hiểu cơ chế synchronous replication và automatic failover Cấu hình truy cập an toàn qua Security Groups Cơ sở dữ liệu NoSQL:\nThiết kế bảng DynamoDB với key schema phù hợp Hiểu sự khác biệt Query (hiệu quả) vs Scan (tốn kém) Triển khai GSI cho các mẫu truy vấn linh hoạt Tầng Caching:\nTriển khai ElastiCache Redis cho application caching Áp dụng Lazy Loading pattern giảm tải RDS Đặt cache trong Private Subnet để tối ưu latency Khái niệm quan trọng:\nManaged services giảm gánh nặng vận hành Multi-AZ đảm bảo tính liên tục kinh doanh Lựa chọn database phù hợp theo use case (SQL vs NoSQL) "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong quá trình thực tập, em đã tham gia 4 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là những món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 - Ho Chi Minh City Connect Edition for Builders (Track 1: GenAI \u0026amp; Data)\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Bến Nghé, Quận 1, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: AWS Cloud Mastery Series #1: GENERATIVE AI, RAG \u0026amp; AWS AGENTIC AI\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Bến Nghé, Quận 1, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: AWS Cloud Mastery Series #2: From DevOps, IaC to Containers \u0026amp; Observability\nThời gian: 08:30 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Bến Nghé, Quận 1, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series #3: Cloud Security \u0026amp; Operations Mastery\nThời gian: 08:30 ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Bến Nghé, Quận 1, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;AWS Cloud Mastery Series #3: Cloud Security \u0026amp; Operations Mastery\u0026rdquo; I. TỔNG QUAN SỰ KIỆN Tên sự kiện: AWS Cloud Mastery Series #3: Cloud Security \u0026amp; Operations Mastery\nMục tiêu tham dự:\nSystem Thinking: Chuyển đổi từ quản lý hạ tầng truyền thống sang mô hình Cloud-Native Security Governance Foundation: Làm chủ quản lý môi trường đa tài khoản sử dụng AWS Organizations và SCPs Defense in Depth: Triển khai bảo mật nhiều lớp kết hợp Identity, Network và Data protection để loại bỏ Single Points of Failure Automated Response: Chuyển từ phản ứng sự cố thủ công sang tự động hóa khắc phục để giảm thiểu độ trễ con người Danh Sách Diễn Giả:\nSự kiện quy tụ đội ngũ chuyên gia hàng đầu từ cộng đồng AWS, bao gồm các AWS Community Builders, Cloud Engineers và các thành viên nòng cốt của chương trình First Cloud Journey:\nĐại diện AWS Cloud Clubs: Các Captains từ HCMUTE, SGU, PTIT, HUFLIT (Le Vu Xuan An, Tran Duc Anh, Tran Doan Cong Ly, Danh Hoang Hieu Nghi) Mảng Identity \u0026amp; Governance: Huynh Hoang Long, Dinh Le Hoang Anh (AWS Community Builders) Mảng Detection \u0026amp; Monitoring: Tran Duc Anh, Nguyen Tuan Thinh, Nguyen Do Thanh Dat Mảng Network Security: Kha Van (Cloud Security Engineer | AWS Community Builder) Mảng Data Protection: Thinh Lam, Viet Nguyen Mảng Incident Response: Mendel Grabski (Long) - ex Head of Security \u0026amp; DevOps, Tinh Truong - Platform Engineer II. NỘI DUNG KIẾN THỨC TRỌNG TÂM Dựa trên các phiên chia sẻ chuyên sâu từ AWS Community Builders và Cloud Security Engineers, tôi đã cấu trúc các kiến thức cốt lõi thành các trụ cột sau:\n1. Identity \u0026amp; Governance (Nền tảng) Security trong Cloud bắt đầu bằng việc kiểm soát \u0026ldquo;Ai có thể làm gì.\u0026rdquo;\nModern IAM Mindset: Trong Cloud, Identity chính là Firewall mới.\nCredential Spectrum: Chuyển đổi bắt buộc từ Long-term Credentials (Permanent Access Keys - Rủi ro cao) sang Short-term Credentials (STS tokens - Tự động hết hạn).\nLeast Privilege: Tránh sử dụng ký tự đại diện (*) trong policies.\nGovernance at Scale:\nAWS Organizations: Cấu trúc tài khoản thành các Organizational Units (OUs) như Security, Shared Services và Workloads để cô lập rủi ro Service Control Policies (SCPs): Đóng vai trò \u0026ldquo;Hiến pháp\u0026rdquo; của tổ chức. SCPs thiết lập Guardrails (ví dụ: cấm vô hiệu hóa CloudTrail) áp dụng cho tất cả tài khoản, bao gồm cả Admins 2. Visibility \u0026amp; Detection \u0026ldquo;Bạn không thể bảo vệ những gì bạn không thể nhìn thấy.\u0026rdquo;\nAmazon GuardDuty (Intelligent Scout):\nSử dụng Machine Learning để phát hiện bất thường dựa trên ba nguồn dữ liệu nền tảng: CloudTrail, VPC Flow Logs và DNS Logs Runtime Monitoring: Sử dụng agent nhẹ để phát hiện các mối đe dọa sâu ở cấp OS như sửa đổi file hoặc leo thang đặc quyền AWS Security Hub (Command Center):\nGiải quyết \u0026ldquo;alert fatigue\u0026rdquo; bằng cách chuẩn hóa các phát hiện từ nhiều công cụ khác nhau (GuardDuty, Inspector, Macie) thành một định dạng duy nhất (ASFF) Hoạt động như công cụ CSPM (Cloud Security Posture Management) để kiểm tra tuân thủ các tiêu chuẩn CIS hoặc PCI-DSS 3. Network Security (The Digital Fortress) Triển khai Defense-in-Depth từ Edge đến Core.\nVPC Fundamentals:\nSecurity Groups (Stateful): Áp dụng Micro-segmentation sử dụng Reference IDs (ví dụ: SG-DB chỉ cho phép traffic từ SG-App) thay vì whitelist địa chỉ IP NACLs (Stateless): Lớp lọc thô ở ranh giới Subnet Advanced Filtering:\nDNS Firewall (Route 53 Resolver): Chặn kết nối đến các máy chủ Command \u0026amp; Control (C2) trong quá trình phân giải domain AWS Network Firewall: Cung cấp Deep Packet Inspection (DPI) với Intrusion Prevention System (IPS) tương thích với quy tắc Suricata Modern Architecture: Sử dụng AWS Transit Gateway để tập trung hóa lưu lượng mạng và đơn giản hóa việc kiểm tra mà không cần định tuyến \u0026ldquo;Inspection VPC\u0026rdquo; phức tạp.\n4. Data Protection Envelope Encryption: Cơ chế đảm bảo hiệu suất và bảo mật:\n$$Master\\ Key \\rightarrow Encrypts \\rightarrow Data\\ Key \\rightarrow Encrypts \\rightarrow Actual\\ Data$$\nSecrets Management: Thay thế thông tin xác thực hardcoded bằng AWS Secrets Manager, cho phép Automatic Rotation mật khẩu database thông qua Lambda.\nInfrastructure Encryption: Tận dụng AWS Nitro System để giảm tải các tác vụ mã hóa sang phần cứng chuyên dụng, đảm bảo Zero Performance Impact.\n5. Incident Response Prevention Strategy: Loại bỏ \u0026ldquo;ClickOps\u0026rdquo; và bắt buộc Infrastructure as Code (IaC) để ngăn chặn configuration drift.\nThe 5-Step Standard: $$Preparation \\rightarrow Detection \\rightarrow Containment \\rightarrow Eradication\\ \u0026amp;\\ Recovery \\rightarrow Post\\text{-}Incident$$\nAutomation: Sử dụng EventBridge + Lambda để tự động cô lập các instance bị xâm phạm hoặc khắc phục các bucket public trong vài giây, đua với tốc độ tấn công.\nIII. ĐÁNH GIÁ \u0026amp; BÀI HỌC KINH NGHIỆM Workshop này là một bước ngoặt trong hiểu biết của tôi về Cloud Security:\n1. Chuyển đổi từ \u0026ldquo;Perimeter Security\u0026rdquo; sang \u0026ldquo;Identity Security\u0026rdquo; Tôi nhận ra rằng khái niệm \u0026ldquo;Firewall\u0026rdquo; truyền thống không còn đủ. Trong môi trường cloud phân tán, Identity chính là ranh giới thực sự. Quản lý credentials (chuyển sang Short-term tokens) và thực thi Least Privilege quan trọng hơn việc chỉ chặn ports.\n2. Sức mạnh của \u0026ldquo;Guardrails\u0026rdquo; hơn \u0026ldquo;Gatekeepers\u0026rdquo; Khái niệm SCPs (Service Control Policies) rất ấn tượng với tôi. Thay vì đóng vai trò \u0026ldquo;Gatekeeper\u0026rdquo; kiểm tra từng hành động của developer (làm chậm sự đổi mới), tôi nên đóng vai trò Platform Engineer xây dựng \u0026ldquo;Guardrails.\u0026rdquo; Điều này cho phép developers chạy nhanh trong các ranh giới an toàn được xác định, ngăn chặn các lỗi nghiêm trọng (như vô hiệu hóa logging) một cách lập trình.\n3. Automation là cách duy nhất để thắng Chiến lược \u0026ldquo;Sleep Better\u0026rdquo; không phải về việc thuê thêm nhân viên bảo mật, mà là về tự động hóa. Demo thực tế về EventBridge + Lambda đã chứng minh rằng con người không thể đánh bại tốc độ máy móc. Phản ứng bảo mật phải được điều khiển bằng code để ngay lập tức ngăn chặn các mối đe dọa ngay khi chúng được phát hiện.\nIV. KẾT LUẬN Series \u0026ldquo;Cloud Security \u0026amp; Operations Mastery\u0026rdquo; cung cấp một framework toàn diện:\nGovernance: Bắt đầu với quản lý Identity nghiêm ngặt và các chính sách Organizational Defense: Bảo mật nhiều lớp trên Network và Data (Encryption) Response: Dựa vào Automation để đảm bảo tính liên tục của business Kiến thức này trao quyền cho tôi không chỉ xây dựng các hệ thống hoạt động được mà còn thiết kế các kiến trúc secure by default và có khả năng phục hồi trước các mối đe dọa hiện đại.\nMột số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của bạn tại đây Tổng thể, workshop đã mang lại góc nhìn toàn diện về bảo mật Cloud hiện đại, từ Identity \u0026amp; Governance, Visibility \u0026amp; Detection, Network Security, Data Protection đến Incident Response tự động hóa, giúp tôi xây dựng hệ thống an toàn và bền vững trên AWS.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"Mô phỏng On-premises DNS ","tags":[],"description":"","content":"AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.4-deploy-backend/","title":"Triển khai Backend API","tags":[],"description":"","content":"Triển khai Backend API với FastAPI Trong phần này, bạn sẽ thiết lập máy chủ backend FastAPI điều phối AI agent sử dụng Strands SDK.\nBước 1: Clone hoặc Tạo Cấu trúc Dự án Tạo thư mục mới cho backend:\nmkdir ev-rental-backend cd ev-rental-backend Cấu trúc dự án:\nev-rental-backend/ ├── app/ │ ├── __init__.py │ ├── main.py # Ứng dụng FastAPI │ ├── agent.py # Thiết lập Strands Agent │ ├── tools.py # Công cụ Agent (tìm xe, trạm) │ └── database.py # Kết nối PostgreSQL ├── requirements.txt # Thư viện Python ├── .env # Biến môi trường └── README.md Bước 2: Cài đặt Thư viện Tạo file requirements.txt:\nfastapi==0.104.1 uvicorn[standard]==0.24.0 strands-agent-sdk==0.1.5 boto3==1.34.10 psycopg2-binary==2.9.9 sqlalchemy==2.0.23 pydantic==2.5.2 python-dotenv==1.0.0 httpx==0.25.2 Cài đặt các thư viện:\n# Tạo môi trường ảo python -m venv venv # Kích hoạt môi trường ảo # Windows: venv\\Scripts\\activate # macOS/Linux: source venv/bin/activate # Cài đặt packages pip install -r requirements.txt Bước 3: Cấu hình Biến Môi trường Tạo file .env với thông tin AWS và Knowledge Base ID:\n# AWS Credentials AWS_ACCESS_KEY_ID=YOUR_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY=YOUR_SECRET_ACCESS_KEY AWS_REGION=us-west-2 # Cấu hình Bedrock BEDROCK_MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0 KNOWLEDGE_BASE_ID=89CI1JSSE4 # Cấu hình Database DATABASE_URL=postgresql://postgres:password@localhost:5432/ev_rental_db # Cấu hình API BACKEND_API_URL=http://localhost:8080 ⚠️ Lưu ý Bảo mật:\nKhông bao giờ commit .env lên Git Thêm .env vào .gitignore Bước 4: Tạo Database Models Tạo file app/database.py:\nfrom sqlalchemy import create_engine, Column, Integer, String, Text, DateTime from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import sessionmaker from datetime import datetime import os DATABASE_URL = os.getenv(\u0026#34;DATABASE_URL\u0026#34;) engine = create_engine(DATABASE_URL) SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine) Base = declarative_base() class ChatHistory(Base): __tablename__ = \u0026#34;chat_history\u0026#34; id = Column(Integer, primary_key=True, index=True) session_id = Column(String, index=True) user_message = Column(Text) agent_response = Column(Text) timestamp = Column(DateTime, default=datetime.utcnow) # Tạo bảng Base.metadata.create_all(bind=engine) Bước 5: Tạo Agent Tools Tạo file app/tools.py:\nimport httpx import os from typing import List, Dict BACKEND_API_URL = os.getenv(\u0026#34;BACKEND_API_URL\u0026#34;, \u0026#34;http://localhost:8080\u0026#34;) async def search_vehicles(location: str = None, model: str = None) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Tìm kiếm xe có sẵn\u0026#34;\u0026#34;\u0026#34; async with httpx.AsyncClient() as client: params = {} if location: params[\u0026#34;location\u0026#34;] = location if model: params[\u0026#34;model\u0026#34;] = model response = await client.get(f\u0026#34;{BACKEND_API_URL}/api/vehicles\u0026#34;, params=params) return response.json() async def search_stations(city: str = None) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Tìm kiếm trạm sạc\u0026#34;\u0026#34;\u0026#34; async with httpx.AsyncClient() as client: params = {} if city: params[\u0026#34;city\u0026#34;] = city response = await client.get(f\u0026#34;{BACKEND_API_URL}/api/stations\u0026#34;, params=params) return response.json() Bước 6: Thiết lập Strands Agent Tạo file app/agent.py:\nimport boto3 import os from strands_agent import Agent, Tool # Khởi tạo Bedrock client bedrock_client = boto3.client( \u0026#39;bedrock-runtime\u0026#39;, region_name=os.getenv(\u0026#39;AWS_REGION\u0026#39;), aws_access_key_id=os.getenv(\u0026#39;AWS_ACCESS_KEY_ID\u0026#39;), aws_secret_access_key=os.getenv(\u0026#39;AWS_SECRET_ACCESS_KEY\u0026#39;) ) # Khởi tạo Knowledge Base client bedrock_agent_client = boto3.client( \u0026#39;bedrock-agent-runtime\u0026#39;, region_name=os.getenv(\u0026#39;AWS_REGION\u0026#39;), aws_access_key_id=os.getenv(\u0026#39;AWS_ACCESS_KEY_ID\u0026#39;), aws_secret_access_key=os.getenv(\u0026#39;AWS_SECRET_ACCESS_KEY\u0026#39;) ) # Tạo Agent agent = Agent( model_id=os.getenv(\u0026#39;BEDROCK_MODEL_ID\u0026#39;), client=bedrock_client, knowledge_base_id=os.getenv(\u0026#39;KNOWLEDGE_BASE_ID\u0026#39;), tools=[ Tool( name=\u0026#34;search_vehicles\u0026#34;, description=\u0026#34;Tìm kiếm xe điện có sẵn để thuê\u0026#34;, function=search_vehicles ), Tool( name=\u0026#34;search_stations\u0026#34;, description=\u0026#34;Tìm trạm sạc gần đó\u0026#34;, function=search_stations ) ] ) Bước 7: Tạo Ứng dụng FastAPI Tạo file app/main.py:\nfrom fastapi import FastAPI, HTTPException from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel from app.agent import agent from app.database import SessionLocal, ChatHistory import uuid app = FastAPI(title=\u0026#34;EV Rental AI Agent API\u0026#34;) # Bật CORS app.add_middleware( CORSMiddleware, allow_origins=[\u0026#34;*\u0026#34;], allow_credentials=True, allow_methods=[\u0026#34;*\u0026#34;], allow_headers=[\u0026#34;*\u0026#34;], ) class ChatRequest(BaseModel): message: str session_id: str = None class ChatResponse(BaseModel): response: str session_id: str data: dict = None @app.post(\u0026#34;/chat\u0026#34;, response_model=ChatResponse) async def chat(request: ChatRequest): try: # Tạo session ID nếu chưa có session_id = request.session_id or str(uuid.uuid4()) # Lấy phản hồi từ agent agent_response = await agent.run(request.message) # Lưu vào database db = SessionLocal() chat_record = ChatHistory( session_id=session_id, user_message=request.message, agent_response=agent_response[\u0026#34;response\u0026#34;] ) db.add(chat_record) db.commit() db.close() return ChatResponse( response=agent_response[\u0026#34;response\u0026#34;], session_id=session_id, data=agent_response.get(\u0026#34;data\u0026#34;) ) except Exception as e: raise HTTPException(status_code=500, detail=str(e)) @app.get(\u0026#34;/health\u0026#34;) async def health_check(): return {\u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;} Bước 8: Chạy Backend Server Khởi động máy chủ FastAPI:\n# Đảm bảo môi trường ảo đã được kích hoạt uvicorn app.main:app --reload --port 8000 # Bạn sẽ thấy: # INFO: Uvicorn running on http://127.0.0.1:8000 # INFO: Application startup complete. Bước 9: Kiểm tra API Kiểm tra endpoint health:\ncurl http://localhost:8000/health # Kết quả: {\u0026#34;status\u0026#34;:\u0026#34;healthy\u0026#34;} Kiểm tra endpoint chat:\ncurl -X POST http://localhost:8000/chat \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;message\u0026#34;: \u0026#34;Chính sách thuê xe của bạn là gì?\u0026#34;}\u0026#39; Kết quả mong đợi:\n{ \u0026#34;response\u0026#34;: \u0026#34;## 📋 Chính sách thuê xe VinFast\\n\\n### 📄 Giấy tờ cần thiết:\\n- CMND/CCCD...\u0026#34;, \u0026#34;session_id\u0026#34;: \u0026#34;abc123-...\u0026#34;, \u0026#34;data\u0026#34;: null } Checklist Xác minh Trước khi tiếp tục, đảm bảo:\n✅ Môi trường ảo đã được tạo và kích hoạt ✅ Tất cả thư viện đã được cài đặt ✅ File .env đã được cấu hình với AWS credentials ✅ PostgreSQL database đang chạy và kết nối được ✅ Máy chủ FastAPI đang chạy trên cổng 8000 ✅ Endpoint health check trả về {\u0026quot;status\u0026quot;:\u0026quot;healthy\u0026quot;} ✅ Endpoint chat trả về phản hồi hợp lệ Xử lý Sự cố Vấn đề: \u0026ldquo;ModuleNotFoundError\u0026rdquo;\nGiải pháp: Đảm bảo môi trường ảo đã được kích hoạt và thư viện đã cài đặt Vấn đề: \u0026ldquo;Database connection failed\u0026rdquo;\nKiểm tra PostgreSQL đang chạy Xác minh DATABASE_URL trong .env Test kết nối: psql -h localhost -U postgres -d ev_rental_db Vấn đề: \u0026ldquo;Bedrock ValidationException\u0026rdquo;\nXác minh AWS credentials trong .env Đảm bảo quyền truy cập model đã được cấp trong Bedrock console Kiểm tra KNOWLEDGE_BASE_ID chính xác Tiếp theo: Chuyển sang Triển khai Frontend để tạo giao diện chat React.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.4-s3-onprem/","title":"Truy cập S3 từ môi trường truyền thống","tags":[],"description":"","content":"Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Tuần 4: Khả năng mở rộng, Giám sát và Mạng phân phối (29/09 – 03/10) Mục tiêu: Tự động hóa khả năng mở rộng hệ thống, thiết lập giám sát toàn diện và tối ưu hóa phân phối nội dung toàn cầu.\nCác công việc đã hoàn thành trong tuần: Ngày Thứ Nội dung Hoạt động chi tiết 29/09 2 EC2 Auto Scaling - Tạo Launch Templates với AMI, Instance Type, Security Group\n- Thiết lập Auto Scaling Group (Min=2, Max=4, Desired=2)\n- Cấu hình Target Tracking Scaling Policy (CPU 50%) 30/09 3 Giám sát Amazon CloudWatch - Theo dõi các metrics chuẩn (CPU, Disk I/O, Network)\n- Cài đặt CloudWatch Agent cho Memory metrics\n- Tạo Alarms với SNS notifications 01/10 4 Giám sát Nâng cao \u0026amp; Logs - Cấu hình CloudWatch Agent đẩy application logs\n- Tạo CloudWatch Dashboard tổng quan sức khỏe hệ thống\n- Tìm hiểu tích hợp Grafana 02/10 5 Amazon Route 53 DNS - Tạo Hosted Zone quản lý tên miền\n- Thực hành các routing policies: Simple, Failover, Latency-based\n- Cấu hình Health Checks cho automatic failover 03/10 6 Amazon CloudFront CDN - Triển khai CloudFront distribution cho S3 static content\n- Cấu hình OAC (Origin Access Control)\n- Tùy chỉnh TTL caching policies Kết quả đạt được tuần 4: Auto Scaling:\nTriển khai Auto Scaling Group với Launch Templates Test scale out/in với công cụ stress Tích hợp với Application Load Balancer Monitoring:\nXây dựng CloudWatch Dashboard toàn diện Cấu hình alarms cho CPU, Memory, Disk metrics Thiết lập SNS notifications cho alerts DNS \u0026amp; CDN:\nCấu hình Route 53 với nhiều routing policies Triển khai CloudFront cho phân phối nội dung toàn cầu Áp dụng OAC cho truy cập S3 an toàn qua CDN Khái niệm quan trọng:\nHorizontal scaling với Auto Scaling Groups Giám sát chủ động vs xử lý sự cố bị động Edge locations cho phân phối nội dung độ trễ thấp "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.5-deploy-frontend/","title":"Triển khai Frontend","tags":[],"description":"","content":"Triển khai Giao diện React Frontend Trong phần này, bạn sẽ thiết lập và chạy giao diện chat React kết nối với backend FastAPI.\nBước 1: Clone hoặc Tạo Dự án React Tạo ứng dụng React mới:\n# Sử dụng Create React App npx create-react-app ev-rental-frontend cd ev-rental-frontend # Hoặc clone repository có sẵn git clone https://github.com/your-org/ev-rental-frontend.git cd ev-rental-frontend Bước 2: Cài đặt Thư viện Cài đặt các gói npm cần thiết:\n# Thư viện cốt lõi npm install axios react-markdown npm install @chakra-ui/react @emotion/react @emotion/styled framer-motion npm install react-icons # Hoặc dùng package.json npm install Ví dụ dependencies trong package.json:\n{ \u0026#34;dependencies\u0026#34;: { \u0026#34;react\u0026#34;: \u0026#34;^18.2.0\u0026#34;, \u0026#34;react-dom\u0026#34;: \u0026#34;^18.2.0\u0026#34;, \u0026#34;axios\u0026#34;: \u0026#34;^1.6.2\u0026#34;, \u0026#34;@chakra-ui/react\u0026#34;: \u0026#34;^2.8.2\u0026#34;, \u0026#34;@emotion/react\u0026#34;: \u0026#34;^11.11.1\u0026#34;, \u0026#34;@emotion/styled\u0026#34;: \u0026#34;^11.11.0\u0026#34;, \u0026#34;framer-motion\u0026#34;: \u0026#34;^10.16.16\u0026#34;, \u0026#34;react-markdown\u0026#34;: \u0026#34;^9.0.1\u0026#34;, \u0026#34;react-icons\u0026#34;: \u0026#34;^4.12.0\u0026#34; } } Bước 3: Cấu trúc Dự án Frontend của bạn nên có cấu trúc như sau:\nev-rental-frontend/ ├── public/ │ ├── index.html │ └── favicon.ico ├── src/ │ ├── App.js # Component chính │ ├── index.js # Entry point │ ├── components/ │ │ ├── ChatInterface.js # Component giao diện chat │ │ ├── MessageList.js # Hiển thị tin nhắn │ │ └── InputBox.js # Nhập liệu người dùng │ ├── services/ │ │ └── api.js # Gọi API tới backend │ ├── utils/ │ │ └── constants.js # Cấu hình │ └── styles/ │ └── App.css ├── package.json └── .env Bước 4: Cấu hình Biến Môi trường Tạo file .env ở thư mục gốc dự án:\n# .env REACT_APP_API_URL=http://localhost:8000 REACT_APP_API_BASE_PATH=/api ⚠️ Quan trọng: Trong React, biến môi trường phải bắt đầu với tiền tố REACT_APP_.\nBước 5: Tạo API Service Tạo file src/services/api.js:\nimport axios from \u0026#39;axios\u0026#39;; const API_URL = process.env.REACT_APP_API_URL || \u0026#39;http://localhost:8000\u0026#39;; const api = axios.create({ baseURL: API_URL, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, }, }); export const sendMessage = async (sessionId, message) =\u0026gt; { try { const response = await api.post(\u0026#39;/api/chat\u0026#39;, { session_id: sessionId, message: message, }); return response.data; } catch (error) { console.error(\u0026#39;Lỗi API:\u0026#39;, error); throw error; } }; export default api; Bước 6: Tạo Component Giao diện Chat Tạo file src/components/ChatInterface.js:\nimport React, { useState, useEffect, useRef } from \u0026#39;react\u0026#39;; import { Box, VStack, HStack, Input, Button, Text, Container, Heading, } from \u0026#39;@chakra-ui/react\u0026#39;; import ReactMarkdown from \u0026#39;react-markdown\u0026#39;; import { sendMessage } from \u0026#39;../services/api\u0026#39;; function ChatInterface() { const [messages, setMessages] = useState([]); const [input, setInput] = useState(\u0026#39;\u0026#39;); const [loading, setLoading] = useState(false); const [sessionId] = useState(() =\u0026gt; `session-${Date.now()}-${Math.random().toString(36).substr(2, 9)}` ); const messagesEndRef = useRef(null); const scrollToBottom = () =\u0026gt; { messagesEndRef.current?.scrollIntoView({ behavior: \u0026#39;smooth\u0026#39; }); }; useEffect(() =\u0026gt; { scrollToBottom(); }, [messages]); const handleSend = async () =\u0026gt; { if (!input.trim()) return; const userMessage = { role: \u0026#39;user\u0026#39;, content: input }; setMessages((prev) =\u0026gt; [...prev, userMessage]); setInput(\u0026#39;\u0026#39;); setLoading(true); try { const response = await sendMessage(sessionId, input); const assistantMessage = { role: \u0026#39;assistant\u0026#39;, content: response.response, data: response.data, }; setMessages((prev) =\u0026gt; [...prev, assistantMessage]); } catch (error) { const errorMessage = { role: \u0026#39;error\u0026#39;, content: \u0026#39;Không thể nhận phản hồi. Vui lòng thử lại.\u0026#39;, }; setMessages((prev) =\u0026gt; [...prev, errorMessage]); } finally { setLoading(false); } }; return ( \u0026lt;Container maxW=\u0026#34;container.md\u0026#34; py={8}\u0026gt; \u0026lt;VStack spacing={4} align=\u0026#34;stretch\u0026#34;\u0026gt; \u0026lt;Heading size=\u0026#34;lg\u0026#34;\u0026gt;🚗 EV Rental AI Agent\u0026lt;/Heading\u0026gt; \u0026lt;Box border=\u0026#34;1px\u0026#34; borderColor=\u0026#34;gray.200\u0026#34; borderRadius=\u0026#34;lg\u0026#34; p={4} h=\u0026#34;500px\u0026#34; overflowY=\u0026#34;auto\u0026#34; bg=\u0026#34;gray.50\u0026#34; \u0026gt; \u0026lt;VStack spacing={3} align=\u0026#34;stretch\u0026#34;\u0026gt; {messages.map((msg, idx) =\u0026gt; ( \u0026lt;Box key={idx} alignSelf={msg.role === \u0026#39;user\u0026#39; ? \u0026#39;flex-end\u0026#39; : \u0026#39;flex-start\u0026#39;} maxW=\u0026#34;80%\u0026#34; bg={msg.role === \u0026#39;user\u0026#39; ? \u0026#39;blue.500\u0026#39; : \u0026#39;white\u0026#39;} color={msg.role === \u0026#39;user\u0026#39; ? \u0026#39;white\u0026#39; : \u0026#39;black\u0026#39;} p={3} borderRadius=\u0026#34;lg\u0026#34; boxShadow=\u0026#34;sm\u0026#34; \u0026gt; {msg.role === \u0026#39;assistant\u0026#39; ? ( \u0026lt;ReactMarkdown\u0026gt;{msg.content}\u0026lt;/ReactMarkdown\u0026gt; ) : ( \u0026lt;Text\u0026gt;{msg.content}\u0026lt;/Text\u0026gt; )} \u0026lt;/Box\u0026gt; ))} {loading \u0026amp;\u0026amp; ( \u0026lt;Box alignSelf=\u0026#34;flex-start\u0026#34; maxW=\u0026#34;80%\u0026#34;\u0026gt; \u0026lt;Text color=\u0026#34;gray.500\u0026#34;\u0026gt;Đang nhập...\u0026lt;/Text\u0026gt; \u0026lt;/Box\u0026gt; )} \u0026lt;div ref={messagesEndRef} /\u0026gt; \u0026lt;/VStack\u0026gt; \u0026lt;/Box\u0026gt; \u0026lt;HStack\u0026gt; \u0026lt;Input value={input} onChange={(e) =\u0026gt; setInput(e.target.value)} onKeyPress={(e) =\u0026gt; e.key === \u0026#39;Enter\u0026#39; \u0026amp;\u0026amp; handleSend()} placeholder=\u0026#34;Hỏi về thuê xe, chính sách, hoặc trạm sạc...\u0026#34; disabled={loading} /\u0026gt; \u0026lt;Button onClick={handleSend} colorScheme=\u0026#34;blue\u0026#34; isLoading={loading} disabled={loading} \u0026gt; Gửi \u0026lt;/Button\u0026gt; \u0026lt;/HStack\u0026gt; \u0026lt;/VStack\u0026gt; \u0026lt;/Container\u0026gt; ); } export default ChatInterface; Bước 7: Cập nhật App.js Cập nhật file src/App.js:\nimport React from \u0026#39;react\u0026#39;; import { ChakraProvider } from \u0026#39;@chakra-ui/react\u0026#39;; import ChatInterface from \u0026#39;./components/ChatInterface\u0026#39;; function App() { return ( \u0026lt;ChakraProvider\u0026gt; \u0026lt;ChatInterface /\u0026gt; \u0026lt;/ChakraProvider\u0026gt; ); } export default App; Bước 8: Chạy Frontend Khởi động máy chủ phát triển React:\nnpm start Kết quả mong đợi:\nCompiled successfully! You can now view ev-rental-frontend in the browser. Local: http://localhost:3000 On Your Network: http://192.168.1.10:3000 Ứng dụng sẽ tự động mở trong trình duyệt tại http://localhost:3000.\nBước 9: Kiểm tra Giao diện Chat Thử các câu hỏi mẫu:\nTruy vấn Knowledge Base:\n\u0026ldquo;Chính sách thuê xe là gì?\u0026rdquo; \u0026ldquo;Tôi cần giấy tờ gì để thuê xe?\u0026rdquo; Tìm kiếm Xe:\n\u0026ldquo;Tìm xe VinFast VF8 ở Hà Nội từ ngày 20/12\u0026rdquo; \u0026ldquo;Có xe nào available?\u0026rdquo; Trạm Sạc:\n\u0026ldquo;Trạm sạc gần Hoàn Kiếm\u0026rdquo; \u0026ldquo;Tìm trạm sạc ở Quận 1\u0026rdquo; Danh sách Kiểm tra Trước khi tiếp tục, đảm bảo:\n✅ Đã cài đặt Node.js và npm ✅ Tất cả thư viện đã cài đặt thành công ✅ File .env đã cấu hình URL backend ✅ Backend server đang chạy trên cổng 8000 ✅ Frontend đang chạy trên cổng 3000 ✅ Giao diện chat tải không có lỗi ✅ Có thể gửi tin nhắn và nhận phản hồi ✅ Định dạng Markdown hiển thị đúng Xử lý Sự cố Lỗi: \u0026ldquo;Module not found\u0026rdquo;\nGiải pháp: Xóa node_modules và chạy lại npm install Kiểm tra phiên bản trong package.json Lỗi: \u0026ldquo;Network Error\u0026rdquo; khi gửi tin nhắn\nKiểm tra backend đang chạy: curl http://localhost:8000/health Xác minh REACT_APP_API_URL trong .env Kiểm tra console trình duyệt có lỗi CORS Lỗi: \u0026ldquo;CORS policy error\u0026rdquo;\nĐảm bảo backend có cấu hình CORS middleware Kiểm tra allow_origins bao gồm http://localhost:3000 Lỗi: Cổng 3000 đã được sử dụng\nĐổi cổng: PORT=3001 npm start Hoặc kill process hiện tại Lỗi: Markdown không render\nXác minh react-markdown đã được cài đặt Kiểm tra câu lệnh import trong ChatInterface.js Tiếp theo: Chuyển sang Testing để xác minh tất cả tính năng hoạt động đúng.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.5-policy/","title":"VPC Endpoint Policies","tags":[],"description":"","content":"Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Tuần 5: Tư duy Vận hành và Hạ tầng dưới dạng Mã (06/10 - 10/10) Mục tiêu: Loại bỏ thao tác thủ công, quản lý hạm đội máy chủ quy mô lớn và mã hóa hạ tầng.\nCác công việc đã hoàn thành trong tuần: Ngày Thứ Nội dung Hoạt động chi tiết 06/10 2 AWS Systems Manager - Cấu hình SSM Agent với IAM Role\n- Run Command trên nhiều instances\n- Thu thập software inventory cho auditing 07/10 3 Session Manager Truy cập An toàn - Đóng port 22 (SSH) trên Security Groups\n- Truy cập qua HTTPS Session Manager\n- Log toàn bộ sessions vào S3/CloudWatch 08/10 4 CloudFormation IaC - Viết YAML templates cho VPC và EC2\n- Thực hành tạo, cập nhật, xóa Stack\n- Sử dụng Change Sets và Drift Detection 09/10 5 AWS CDK Cơ bản - Sử dụng TypeScript/Python cho hạ tầng\n- Học các Construct levels (L1, L2, L3)\n- Tạo VPC chỉ với một dòng code 10/10 6 AWS CDK Nâng cao \u0026amp; Workshop - Xây dựng custom Constructs tái sử dụng\n- Xử lý circular dependencies\n- Quản lý biến môi trường với Context Kết quả đạt được tuần 5: Quản lý Hệ thống:\nLoại bỏ quản lý SSH key với Session Manager Chạy commands trên fleet không cần truy cập từng máy Thu thập inventory cho compliance auditing Infrastructure as Code:\nViết CloudFormation templates bằng YAML Hiểu Stack lifecycle và state management Phát hiện configuration drift AWS CDK:\nSử dụng ngôn ngữ lập trình cho hạ tầng Xây dựng Constructs tái sử dụng cho tổ chức Hoàn thành IaC Workshop challenges Khái niệm quan trọng:\nIaC loại bỏ lỗi cấu hình thủ công Session Manager là tiêu chuẩn vàng cho server access CDK cung cấp abstraction cao hơn CloudFormation "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Xây dựng EV Rental AI Agent với AWS Bedrock Tổng quan EV Rental AI Agent là một chatbot thông minh được xây dựng để hỗ trợ khách hàng trong hệ thống cho thuê xe điện VinFast. Workshop này hướng dẫn cách sử dụng AWS Bedrock, Claude 3.5 Sonnet, và Knowledge Bases để tạo một AI đàm thoại có thể:\nTrả lời câu hỏi tự nhiên bằng tiếng Việt Tự động tìm kiếm thông tin từ nhiều nguồn Hiển thị dữ liệu dưới dạng card tương tác trong giao diện chat Tra cứu xe khả dụng và trạm sạc Truy cập chính sách thuê xe và FAQ từ knowledge base Trong workshop này, bạn sẽ học cách:\nThiết lập AWS Bedrock - Kích hoạt các AI model và tạo Knowledge Base để truy xuất tài liệu Triển khai Backend API - Xây dựng FastAPI server với Strands Agent SDK cho việc chọn tool thông minh Triển khai Frontend - Tạo giao diện chat React với các component Chakra UI Kiểm thử hệ thống - Tương tác với AI agent và xác minh tất cả chức năng Nội dung Tổng quan Workshop Yêu cầu chuẩn bị Thiết lập AWS Bedrock Triển khai Backend API Triển khai Frontend Kiểm thử AI Agent Dọn dẹp tài nguyên "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.6-testing/","title":"Kiểm thử Hệ thống","tags":[],"description":"","content":"Kiểm thử EV Rental AI Agent Trong phần này, bạn sẽ kiểm thử cả ba tính năng cốt lõi của AI Agent để đảm bảo mọi thứ hoạt động chính xác.\nĐiều kiện Trước khi Kiểm thử Trước khi kiểm thử, đảm bảo:\n✅ Backend server đang chạy tại http://localhost:8000 ✅ Frontend application đang chạy tại http://localhost:3000 ✅ Cơ sở dữ liệu PostgreSQL đang chạy và có dữ liệu test ✅ AWS Bedrock Knowledge Base đã được đồng bộ và sẵn sàng Kịch bản Kiểm thử 1: Tìm kiếm Knowledge Base AI Agent phải có khả năng trả lời câu hỏi về chính sách thuê xe, giá cả và FAQ sử dụng Knowledge Base.\nCâu hỏi Kiểm thử:\nChính sách Thuê xe:\nUser: \u0026#34;Chính sách thuê xe là gì?\u0026#34; Kết quả mong đợi: Agent trả về chi tiết chính sách từ Knowledge Base Giấy tờ Yêu cầu:\nUser: \u0026#34;Tôi cần giấy tờ gì để thuê xe?\u0026#34; Kết quả mong đợi: Agent liệt kê giấy tờ cần thiết (CMND, bằng lái, tiền cọc) Thông tin Giá cả:\nUser: \u0026#34;Giá thuê xe VinFast VF8 là bao nhiêu?\u0026#34; Kết quả mong đợi: Agent cung cấp chi tiết giá từ Knowledge Base Quy trình Đặt xe:\nUser: \u0026#34;Làm thế nào để đặt xe?\u0026#34; Kết quả mong đợi: Agent giải thích quy trình đặt xe từng bước Xác minh:\n✅ Phản hồi bao gồm trích dẫn từ Knowledge Base ✅ Câu trả lời liên quan và chính xác ✅ Định dạng Markdown hiển thị đúng ✅ Thời gian phản hồi dưới 5 giây Kịch bản Kiểm thử 2: Tìm kiếm Xe AI Agent phải tìm kiếm cơ sở dữ liệu PostgreSQL để tìm xe có sẵn theo địa điểm và ngày tháng.\nCâu hỏi Kiểm thử:\nTìm theo Địa điểm:\nUser: \u0026#34;Tìm xe ở Hà Nội\u0026#34; Kết quả mong đợi: Agent liệt kê xe có sẵn ở Hà Nội Tìm theo Model:\nUser: \u0026#34;Có xe VinFast VF8 nào available không?\u0026#34; Kết quả mong đợi: Agent hiển thị xe VF8 với trạng thái sẵn có Tìm theo Khoảng Ngày:\nUser: \u0026#34;Tìm xe VF9 ở Hồ Chí Minh từ ngày 20/12 đến 25/12\u0026#34; Kết quả mong đợi: Agent tìm xe sẵn có trong khoảng ngày đó Tìm theo Khoảng Giá:\nUser: \u0026#34;Xe nào dưới 1 triệu đồng/ngày?\u0026#34; Kết quả mong đợi: Agent lọc xe theo giá Xác minh:\n✅ Agent trích xuất đúng tham số tìm kiếm (địa điểm, model, ngày) ✅ Kết quả bao gồm chi tiết xe (model, giá, địa điểm, trạng thái) ✅ Dữ liệu được lấy từ cơ sở dữ liệu PostgreSQL ✅ Kết quả được định dạng thành bảng hoặc danh sách dễ đọc Định dạng Phản hồi Mong đợi:\n## 🚗 Xe Có Sẵn | Model | Địa điểm | Giá/Ngày | Trạng thái | |-------|----------|----------|------------| | VinFast VF8 | Hà Nội | 800,000đ | Có sẵn | | VinFast VF9 | Hà Nội | 1,200,000đ | Có sẵn | Kịch bản Kiểm thử 3: Tìm Trạm Sạc AI Agent phải tìm trạm sạc gần đó với thông tin sẵn có theo thời gian thực.\nCâu hỏi Kiểm thử:\nTìm theo Quận:\nUser: \u0026#34;Trạm sạc gần Quận Hoàn Kiếm\u0026#34; Kết quả mong đợi: Agent liệt kê trạm sạc ở quận Hoàn Kiếm Tìm theo Địa chỉ:\nUser: \u0026#34;Tìm trạm sạc ở Quận 1, TP.HCM\u0026#34; Kết quả mong đợi: Agent tìm trạm ở Quận 1, TP.HCM Kiểm tra Trạng thái Trạm:\nUser: \u0026#34;Trạm sạc nào còn trống?\u0026#34; Kết quả mong đợi: Agent hiển thị trạm có cổng sạc còn trống Lọc theo Loại Connector:\nUser: \u0026#34;Trạm sạc có CCS2 connector\u0026#34; Kết quả mong đợi: Agent lọc trạm có connector CCS2 Xác minh:\n✅ Agent nhận diện đúng địa điểm từ câu hỏi ✅ Kết quả bao gồm tên trạm, địa chỉ và trạng thái ✅ Các loại connector được liệt kê ✅ Trạng thái sẵn có theo thời gian thực được hiển thị Định dạng Phản hồi Mong đợi:\n## ⚡ Trạm Sạc Gần Bạn ### VinFast Station - Hoàn Kiếm 📍 Địa chỉ: 123 Trần Hưng Đạo, Hoàn Kiếm, Hà Nội 🔌 Connectors: CCS2 (2 sẵn có), CHAdeMO (1 sẵn có) ⏰ Giờ mở cửa: 24/7 ✅ Trạng thái: Có sẵn Kịch bản Kiểm thử 4: Cuộc hội thoại Nhiều lượt Kiểm tra khả năng duy trì ngữ cảnh của agent qua nhiều lượt hội thoại.\nCuộc hội thoại Kiểm thử:\nUser: \u0026#34;Tôi muốn thuê xe VF8\u0026#34; Agent: [Cung cấp thông tin VF8] User: \u0026#34;Giá bao nhiêu?\u0026#34; Agent: [Phải hiểu ngữ cảnh đang nói về giá VF8] User: \u0026#34;Trạm sạc gần đó ở đâu?\u0026#34; Agent: [Phải tìm trạm sạc gần vị trí VF8] Xác minh:\n✅ Agent duy trì ngữ cảnh cuộc hội thoại ✅ Đại từ và tham chiếu được hiểu đúng ✅ Session ID được giữ xuyên suốt các tin nhắn Kịch bản Kiểm thử 5: Xử lý Lỗi Kiểm tra cách agent xử lý các câu hỏi không hợp lệ hoặc không rõ ràng.\nCác Trường hợp Kiểm thử:\nCâu hỏi Mơ hồ:\nUser: \u0026#34;Xe\u0026#34; Kết quả mong đợi: Agent yêu cầu làm rõ Xe Không Có Sẵn:\nUser: \u0026#34;Tìm xe Tesla\u0026#34; Kết quả mong đợi: Agent giải thích Tesla không có, đề xuất thay thế Ngày Không hợp lệ:\nUser: \u0026#34;Thuê xe từ ngày 32/13\u0026#34; Kết quả mong đợi: Agent phát hiện ngày không hợp lệ và yêu cầu sửa Ngoài Phạm vi:\nUser: \u0026#34;Thời tiết hôm nay thế nào?\u0026#34; Kết quả mong đợi: Agent giải thích lịch sự chỉ có thể hỗ trợ về thuê xe EV Xác minh:\n✅ Agent xử lý lỗi một cách mượt mà ✅ Cung cấp thông báo lỗi hữu ích ✅ Đề xuất các phương án thay thế khi có thể Kiểm thử Hiệu năng Kiểm tra hiệu năng hệ thống trong điều kiện sử dụng bình thường:\nCác Chỉ số Cần Theo dõi:\nThời gian Phản hồi:\nTruy vấn Knowledge Base: \u0026lt; 3 giây Tìm kiếm xe: \u0026lt; 2 giây Tìm trạm sạc: \u0026lt; 2 giây Tình trạng API:\ncurl http://localhost:8000/health Kết quả mong đợi: 200 OK với trạng thái healthy\nLog Backend: Kiểm tra lỗi trong console output của FastAPI\nConsole Frontend: Mở browser DevTools → Console\nKhông có lỗi JavaScript Các API call thành công (tab Network) Danh sách Kiểm tra Tích hợp Thực hiện danh sách kiểm tra toàn diện này:\n✅ Tích hợp Knowledge Base:\nAgent có thể truy xuất thông tin chính sách Trích dẫn được bao gồm trong phản hồi Các API call Bedrock thành công ✅ Tích hợp Cơ sở dữ liệu:\nTìm kiếm xe truy vấn PostgreSQL Kết quả chính xác và cập nhật Kết nối cơ sở dữ liệu ổn định ✅ Backend API:\nEndpoint /api/chat hoạt động Endpoint /health phản hồi Quản lý session hoạt động đúng ✅ Frontend UI:\nTin nhắn hiển thị chính xác Nhập liệu người dùng được thu thập Trạng thái loading hoạt động Markdown render đúng Auto-scroll hoạt động ✅ Xử lý Lỗi:\nLỗi mạng được bắt Đầu vào không hợp lệ được xử lý mượt mà Người dùng nhận được phản hồi hữu ích Kiểm thử với Postman (Tùy chọn) Kiểm thử backend API trực tiếp:\n1. Kiểm tra Health:\nGET http://localhost:8000/health 2. Yêu cầu Chat:\nPOST http://localhost:8000/api/chat Content-Type: application/json { \u0026#34;session_id\u0026#34;: \u0026#34;test-session-123\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Chính sách thuê xe là gì?\u0026#34; } Phản hồi Mong đợi:\n{ \u0026#34;response\u0026#34;: \u0026#34;## 📋 Chính sách thuê xe VinFast\\n\\n...\u0026#34;, \u0026#34;data\u0026#34;: null, \u0026#34;session_id\u0026#34;: \u0026#34;test-session-123\u0026#34; } Xử lý Sự cố Kiểm thử Thất bại Vấn đề: Knowledge Base trả về kết quả rỗng\nKiểm tra Knowledge Base đã được đồng bộ trong AWS Console Xác minh KNOWLEDGE_BASE_ID trong .env Test KB trực tiếp trong Bedrock console Vấn đề: Tìm kiếm xe không trả về kết quả\nKiểm tra cơ sở dữ liệu PostgreSQL có dữ liệu test Xác minh chuỗi kết nối DATABASE_URL Chạy truy vấn SQL trực tiếp: SELECT * FROM vehicles; Vấn đề: Không tìm thấy trạm sạc\nXác minh endpoint /stations của backend API hoạt động Kiểm tra dữ liệu trạm trong database Test API call: curl http://localhost:8080/stations Vấn đề: Frontend không kết nối được backend\nKiểm tra REACT_APP_API_URL trong frontend .env Xác minh backend CORS cho phép http://localhost:3000 Kiểm tra console trình duyệt có lỗi network Mẫu Báo cáo Kiểm thử Ghi lại kết quả kiểm thử của bạn:\n## Báo cáo Kiểm thử - EV Rental AI Agent **Ngày:** 2024-12-20 **Người kiểm thử:** Tên của bạn ### Tóm tắt Kết quả - Tổng số Test: 15 - Đạt: 14 - Thất bại: 1 - Tỷ lệ Thành công: 93% ### Kết quả Chi tiết #### Tìm kiếm Knowledge Base - [x] Truy vấn chính sách - ĐẠT - [x] Giấy tờ yêu cầu - ĐẠT - [x] Thông tin giá - ĐẠT - [ ] Quy trình đặt xe - THẤT BẠI (phản hồi chậm) #### Tìm kiếm Xe - [x] Tìm theo địa điểm - ĐẠT - [x] Tìm theo model - ĐẠT - [x] Tìm theo khoảng ngày - ĐẠT #### Tìm Trạm Sạc - [x] Tìm theo quận - ĐẠT - [x] Kiểm tra sẵn có - ĐẠT ### Vấn đề Phát hiện 1. Truy vấn quy trình đặt xe mất 7 giây (\u0026gt; ngưỡng 5s) - Nguyên nhân: Knowledge Base đồng bộ chưa hoàn tất - Sửa: Đồng bộ lại data source ### Khuyến nghị - Theo dõi thời gian phản hồi trong lúc sử dụng cao điểm - Thêm caching cho các câu hỏi thường gặp - Triển khai rate limiting Thành công! 🎉 EV Rental AI Agent của bạn đã được kiểm thử đầy đủ và hoạt động.\nTiếp theo: Chuyển sang Cleanup để xóa tài nguyên và tránh chi phí.\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Tự đánh giá Trong suốt thời gian thực tập tại CÔNG TY TNHH AMAZON WEB SERVICES VIỆT NAM từ 08/09 đến 12/12, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia vào dự án VoltGo (Hệ thống cho thuê xe điện tại điểm cố định) với vai trò Frontend Developer (phát triển giao diện Web Dashboard). Qua đó, tôi đã cải thiện đáng kể các kỹ năng:\nLập trình: Xây dựng giao diện quản trị, triển khai qua AWS Amplify, và xử lý tích hợp API. Phân tích \u0026amp; Tích hợp: Hiểu sâu về luồng dữ liệu giữa Frontend và các dịch vụ AWS. Viết báo cáo \u0026amp; Tài liệu: Kỹ năng document lại các component và quy trình triển khai. Về tác phong, tôi luôn nỗ lực hoàn thành nhiệm vụ chuyên môn được giao. Tuy nhiên, tôi nhận thấy bản thân cần nghiêm túc chấn chỉnh lại tính kỷ luật và quy trình làm việc để đạt hiệu quả tối ưu hơn.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức (Next.js, AWS) vào thực tế, chất lượng code ✅ 2 Khả năng học hỏi Tiếp thu công nghệ mới, học hỏi nhanh ✅ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ✅ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ✅ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ Cần cải thiện Dựa trên quá trình làm việc thực tế, tôi nhận thấy mình cần tập trung khắc phục 3 điểm yếu sau để hoàn thiện bản thân:\nNâng cao tính kỷ luật và tuân thủ quy trình:\nThực trạng: Đôi lúc còn lơ là trong việc chấp hành nghiêm chỉnh các quy định hành chính hoặc giờ giấc của công ty. Hành động: Tôi cam kết rèn luyện tác phong công nghiệp, tuân thủ tuyệt đối nội quy của AWS cũng như bất kỳ tổ chức nào trong tương lai, xem đây là nền tảng cốt lõi của sự chuyên nghiệp. Cải thiện tư duy giải quyết vấn đề:\nThực trạng: Khi hệ thống phát sinh lỗi (bug) phức tạp, tôi thường xử lý theo hướng khắc phục tạm thời thay vì phân tích chiều sâu. Hành động: Tôi sẽ rèn luyện tư duy logic hệ thống, học cách phân tích nguyên nhân gốc rễ (Root Cause Analysis) trước khi bắt tay vào sửa code để đưa ra giải pháp tối ưu và bền vững. Học cách giao tiếp hiệu quả hơn:\nThực trạng: Kỹ năng diễn đạt trong công việc hàng ngày và xử lý tình huống đôi khi còn lúng túng, chưa gãy gọn. Hành động: Tôi sẽ tích cực tham gia thảo luận nhóm, học cách lắng nghe và trình bày vấn đề một cách súc tích, rõ ràng để thông tin được truyền tải chính xác nhất đến đồng nghiệp. "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Tuần 6: Kiến trúc Bảo mật Đa lớp (13/10 - 17/10) Mục tiêu: Xây dựng pháo đài số bảo vệ dữ liệu và ứng dụng trước các mối đe dọa mạng hiện đại.\nCác công việc đã hoàn thành trong tuần: Ngày Thứ Nội dung Hoạt động chi tiết 13/10 2 AWS WAF - Triển khai WAF trên ALB/CloudFront\n- Cấu hình rules chống SQL Injection, XSS\n- Tạo Rate-based rules chống DDoS 14/10 3 AWS KMS Mã hóa - Tạo Customer Managed Keys (CMK)\n- Cấu hình Key Policy phân tách admin/user\n- Kích hoạt mã hóa trên EBS và S3 15/10 4 Secrets Manager - Lưu trữ mật khẩu RDS trong Secrets Manager\n- Cấu hình automatic rotation với Lambda\n- Cập nhật ứng dụng lấy secrets qua API 16/10 5 GuardDuty Phát hiện Mối đe dọa - Kích hoạt intelligent threat detection\n- Phân tích CloudTrail, VPC Flow Logs, DNS Logs\n- Cấu hình EventBridge alerts cho high-severity findings 17/10 6 Amazon Cognito - Tạo User Pool cho app authentication\n- Cấu hình Identity Pool cho temporary AWS credentials\n- Cho phép end users upload trực tiếp lên S3 Kết quả đạt được tuần 6: Bảo mật Ứng dụng:\nTriển khai WAF bảo vệ chống OWASP Top 10 Áp dụng rate limiting chống DDoS Mã hóa Dữ liệu:\nTạo và quản lý CMK với key policies phù hợp Mã hóa data at rest trên EBS, S3, RDS Quản lý Secrets:\nLoại bỏ hardcoded credentials trong ứng dụng Tự động hóa password rotation Phát hiện Mối đe dọa:\nKích hoạt ML-based threat detection với GuardDuty Thiết lập automated alerting cho security incidents Identity Federation:\nXây dựng user authentication với Cognito User Pools Kích hoạt federated access với Identity Pools "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nI. Đánh giá chung 1. Môi trường làm việc\nMôi trường tại FCJ rất chuyên nghiệp và đậm chất công nghệ (\u0026ldquo;Builder culture\u0026rdquo;). Tôi ấn tượng với sự cởi mở trong giao tiếp, nơi thực tập sinh được khuyến khích nêu ý kiến về giải pháp kỹ thuật chứ không chỉ làm theo chỉ đạo. Không gian làm việc kích thích sự sáng tạo, và việc tiếp cận các tài nguyên Cloud của AWS luôn sẵn sàng. Tuy nhiên, do tính chất dự án kỹ thuật cao, đôi khi không khí làm việc hơi căng thẳng, tôi nghĩ việc có thêm các hoạt động \u0026ldquo;Happy Hour\u0026rdquo; ngắn giữa tuần sẽ giúp mọi người giải tỏa áp lực tốt hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor đóng vai trò rất lớn trong sự phát triển của tôi. Với vai trò Frontend phải tích hợp nhiều dịch vụ AWS phức tạp, tôi thường xuyên gặp khó khăn. Mentor đã rất kiên nhẫn, không chỉ chỉ lỗi sai mà còn hướng dẫn tôi cách tư duy để tìm nguyên nhân gốc rễ (Root Cause Analysis). Team Admin hỗ trợ quy trình rất nhanh gọn, giúp tôi tập trung hoàn toàn vào chuyên môn.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc Frontend Developer tại dự án VoltGo hoàn toàn phù hợp với chuyên ngành của tôi nhưng ở mức độ \u0026ldquo;thực chiến\u0026rdquo; cao hơn nhiều. Từ việc chỉ biết viết code giao diện đơn thuần, tôi đã học được cách tư duy về tích hợp hệ thống (System Integration), bảo mật với Cognito và tối ưu trải nghiệm người dùng trên nền tảng Cloud. Đây là bước đệm kiến thức mà trường lớp chưa thể trang bị đủ.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nĐây là khoảng thời gian tôi học được nhiều nhất từ trước đến nay. Về chuyên môn, tôi thành thạo hơn với React Native, Next.js và hệ sinh thái AWS. Về kỹ năng mềm, tôi học được quy trình làm việc Agile, cách quản lý source code và quan trọng nhất là hiểu được tiêu chuẩn của một sản phẩm thương mại (tính ổn định, khả năng mở rộng) khác xa với đồ án sinh viên như thế nào.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nTinh thần \u0026ldquo;Customer Obsession\u0026rdquo; (Ám ảnh khách hàng) và \u0026ldquo;Ownership\u0026rdquo; (Làm chủ) của AWS lan tỏa rất rõ trong team. Mọi người hỗ trợ nhau không kể cấp bậc. Có những thời điểm tôi làm sai ảnh hưởng đến tiến độ chung, thay vì trách móc, cả team đã cùng xúm lại hỗ trợ tôi fix bug. Điều này khiến tôi cảm thấy mình được bao dung và có động lực để sửa đổi tính kỷ luật của bản thân.\n6. Chính sách / phúc lợi cho thực tập sinh\nĐối với tôi, phúc lợi giá trị nhất tại đây không nằm ở vật chất, mà là cơ hội được \u0026rsquo;nhúng mình\u0026rsquo; vào một môi trường quy tụ những chuyên gia Cloud hàng đầu. Việc được làm việc hàng ngày cạnh những Mentor dày dạn kinh nghiệm, được trực tiếp quan sát cách các anh/chị tư duy và giải quyết các bài toán hóc búa là những bài học \u0026rsquo;nghề\u0026rsquo; vô giá mà sách vở không thể dạy được. Đây thực sự là một \u0026lsquo;mỏ vàng\u0026rsquo; tri thức giúp tôi rút ngắn đáng kể thời gian tự mày mò.\nII. Một số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nLà cảm giác \u0026ldquo;Ownership\u0026rdquo; (Làm chủ). Tôi được giao trách nhiệm thực sự với các tính năng quan trọng trên App và Web Dashboard, code của tôi viết ra được chạy trên hệ thống thật chứ không phải chỉ là bài tập mô phỏng.\nĐiều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\nTôi nghĩ chương trình nên bổ sung thêm các buổi đào tạo kỹ năng mềm (\u0026ldquo;Soft-skill workshops\u0026rdquo;) ngay từ đầu kỳ, đặc biệt là về Quản lý thời gian và Kỷ luật công sở. Nhiều sinh viên kỹ thuật như tôi khi mới vào thường bị choáng ngợp và chưa biết cách sắp xếp công việc khoa học, dẫn đến áp lực không đáng có.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nChắc chắn là CÓ. Đây là môi trường lý tưởng để \u0026ldquo;ép\u0026rdquo; bản thân trưởng thành. Dù áp lực cao, nhưng những kiến thức về Cloud và quy trình làm việc chuyên nghiệp thu được sau 3 tháng sẽ là hành trang vô giá cho sự nghiệp sau này.\nIII. Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập?\nTôi đề xuất Mentor có thể thiết lập các buổi \u0026ldquo;Check-point 1:1\u0026rdquo; định kỳ 2 tuần/lần không chỉ để review code mà còn để review về thái độ và tác phong làm việc. Việc nhận feedback sớm và thẳng thắn về kỷ luật hay cách giao tiếp sẽ giúp thực tập sinh nhận ra điểm yếu và điều chỉnh kịp thời trước khi kết thúc kỳ thực tập.\nBạn có muốn tiếp tục chương trình này trong tương lai?\nTôi rất mong muốn có cơ hội quay lại AWS hoặc tiếp tục đồng hành cùng FCJ ở vị trí cao hơn sau khi tôi đã hoàn thiện các kỹ năng còn thiếu sót và tốt nghiệp.\nGóp ý khác (tự do chia sẻ):\nCảm ơn Team FCJ và các Mentor đã tạo ra một sân chơi quá bổ ích. Dù bản thân tôi còn nhiều hạn chế về mặt kỷ luật và giao tiếp trong thời gian qua, nhưng sự kiên nhẫn của mọi người chính là bài học lớn nhất mà tôi nhận được. Chúc chương trình ngày càng thành công!\nKhép lại hành trình tại FCJ, em muốn gửi lời cảm ơn sâu sắc nhất đến những người dẫn đường tâm huyết đã giúp em hoàn thành chặng đường này một cách trọn vẹn.\nĐặc biệt tri ân các anh: Nguyễn Gia Hưng, Văn Hoàng Kha và các anh mentor. Cảm ơn các anh đã luôn support nhiệt tình bất kể ngày đêm, từ những quy trình nhỏ nhất đến việc định hướng tư duy chiến lược.\nSự kiên nhẫn và động viên của các anh chính là hành trang quý giá nhất mà em nhận được. Chúc đội ngũ Admin và Mentor của FCJ luôn mạnh khỏe và thành công!\n"},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/5-workshop/5.7-cleanup/","title":"Dọn dẹp Tài nguyên","tags":[],"description":"","content":"Dọn dẹp Tài nguyên Sau khi hoàn thành workshop, hãy làm theo các bước sau để dọn dẹp tất cả tài nguyên và tránh phí AWS không cần thiết.\nTại sao Dọn dẹp là Quan trọng Tiết kiệm Chi phí: AWS tính phí cho các tài nguyên đang hoạt động như Bedrock Knowledge Bases, S3 storage và các dịch vụ đang chạy Bảo mật: Xóa các credentials IAM không sử dụng để duy trì best practices về bảo mật Tổ chức: Giữ tài khoản AWS của bạn sạch sẽ và có tổ chức Bước 1: Xóa AWS Bedrock Knowledge Base 1.1 Xóa Knowledge Base Mở AWS Bedrock Console Điều hướng đến Knowledge Bases ở thanh bên trái Chọn Knowledge Base của bạn: ev-rental-knowledge-base Click Delete Xác nhận xóa bằng cách nhập tên Knowledge Base Click Delete để xác nhận ⚠️ Lưu ý: Điều này cũng sẽ xóa các kết nối data source liên quan.\n1.2 Xóa S3 Bucket và Documents Mở S3 Console Tìm bucket của bạn: ev-rental-knowledge-docs Chọn bucket Click Empty để xóa tất cả objects Xác nhận bằng cách nhập \u0026ldquo;permanently delete\u0026rdquo; Sau khi làm trống, click Delete trên bucket Xác nhận bằng cách nhập tên bucket Hoặc dùng AWS CLI:\n# Xóa tất cả objects trong bucket aws s3 rm s3://ev-rental-knowledge-docs --recursive # Xóa bucket aws s3 rb s3://ev-rental-knowledge-docs Bước 2: Xóa IAM User và Access Keys 2.1 Xóa Access Keys Mở IAM Console Điều hướng đến Users Chọn user của bạn (ví dụ: bedrock-agent-user) Click vào tab Security credentials Dưới Access keys, tìm access key của bạn Click Delete bên cạnh access key Xác nhận xóa 2.2 Xóa IAM User (Tùy chọn) Nếu bạn đã tạo IAM user riêng cho workshop này:\nTrong IAM Console, chọn user Click Delete user Xác nhận bằng cách check vào ô Click Delete Hoặc dùng AWS CLI:\n# Liệt kê access keys aws iam list-access-keys --user-name bedrock-agent-user # Xóa access key (thay bằng key ID của bạn) aws iam delete-access-key --user-name bedrock-agent-user --access-key-id AKIA5GPEMGJZK6E7PMEB # Xóa user aws iam delete-user --user-name bedrock-agent-user Bước 3: Dừng Các Dịch vụ Local 3.1 Dừng FastAPI Backend Trong terminal nơi FastAPI đang chạy:\nNhấn Ctrl + C để dừng server\nDeactivate virtual environment:\ndeactivate Tùy chọn xóa thư mục dự án:\n# Trên macOS/Linux rm -rf ev-rental-backend # Trên Windows rmdir /s ev-rental-backend 3.2 Dừng React Frontend Trong terminal nơi React đang chạy:\nNhấn Ctrl + C để dừng development server\nTùy chọn xóa thư mục dự án:\n# Trên macOS/Linux rm -rf ev-rental-frontend # Trên Windows rmdir /s ev-rental-frontend 3.3 Dừng PostgreSQL Database Nếu bạn đã cài PostgreSQL local cho workshop này:\nTrên macOS:\n# Dừng PostgreSQL service brew services stop postgresql@14 Trên Linux:\nsudo systemctl stop postgresql Trên Windows:\n# Mở Services (services.msc) # Tìm service \u0026#34;PostgreSQL\u0026#34; # Right-click → Stop 3.4 Xóa Database (Tùy chọn) Nếu bạn muốn xóa hoàn toàn database:\n# Kết nối PostgreSQL psql -U postgres # Xóa database DROP DATABASE ev_rental_db; # Thoát \\q Bước 4: Xóa Các File Environment Xóa các file .env nhạy cảm chứa credentials:\nBackend:\ncd ev-rental-backend rm .env Frontend:\ncd ev-rental-frontend rm .env ⚠️ Lưu ý Bảo mật: Không bao giờ commit file .env vào Git. Luôn thêm chúng vào .gitignore.\nBước 5: Xác minh Dọn dẹp 5.1 Kiểm tra Tài nguyên AWS Xác minh tất cả tài nguyên đã được xóa:\nBedrock Console:\nKhông có Knowledge Bases nào được liệt kê Không có model invocations đang hoạt động S3 Console:\nBucket ev-rental-knowledge-docs đã bị xóa IAM Console:\nAccess keys đã bị xóa IAM user đã bị xóa (nếu bạn chọn xóa) 5.2 Kiểm tra Chi phí AWS Mở AWS Billing Console Kiểm tra Bills cho tháng hiện tại Xác minh các khoản phí: Phí Bedrock sẽ dừng sau khi xóa Knowledge Base Phí S3 storage sẽ dừng sau khi xóa bucket Không có phí compute đang chạy Hoặc dùng AWS CLI:\naws ce get-cost-and-usage \\ --time-period Start=2024-12-01,End=2024-12-31 \\ --granularity MONTHLY \\ --metrics UnblendedCost \\ --group-by Type=SERVICE Chi tiết Chi phí Đây là những gì bạn có thể đã bị tính phí trong workshop:\nDịch vụ Chi phí Ước tính Ghi chú AWS Bedrock - Claude 3.5 Sonnet ~$0.50 - $2.00 Phụ thuộc số lượng truy vấn AWS Bedrock - Knowledge Base ~$0.10 - $0.50 Vector storage và retrieval S3 Storage ~$0.02 Tối thiểu cho documents nhỏ Data Transfer ~$0.05 Thường trong free tier Tổng ~$0.67 - $2.57 Ước tính cho workshop ⚠️ Lưu ý: Hầu hết chi phí đến từ các API calls Bedrock. Càng test lâu, chi phí càng cao.\nDanh sách Kiểm tra Dọn dẹp Trước khi kết thúc, xác minh tất cả mục đã hoàn thành:\nTài nguyên AWS ✅ Bedrock Knowledge Base đã xóa ✅ S3 bucket đã làm trống và xóa ✅ IAM Access Keys đã xóa ✅ IAM User đã xóa (tùy chọn) Tài nguyên Local ✅ FastAPI backend đã dừng ✅ React frontend đã dừng ✅ PostgreSQL database đã dừng ✅ PostgreSQL database đã xóa (tùy chọn) File Nhạy cảm ✅ File .env backend đã xóa ✅ File .env frontend đã xóa ✅ Không có AWS credentials trong các file dự án Xác minh ✅ AWS Console không hiển thị tài nguyên đang hoạt động ✅ Billing dashboard hiển thị phí đã dừng ✅ Các dịch vụ local không chạy Xử lý Sự cố Dọn dẹp Vấn đề: Không thể xóa S3 bucket - \u0026ldquo;Bucket not empty\u0026rdquo;\nGiải pháp: Làm trống tất cả objects trước bằng S3 Console hoặc CLI Lệnh: aws s3 rm s3://bucket-name --recursive Vấn đề: Không thể xóa Knowledge Base - \u0026ldquo;In use\u0026rdquo;\nGiải pháp: Đợi vài phút để các thao tác đang chờ hoàn thành Kiểm tra xem có API calls nào vẫn đang tham chiếu đến nó Vấn đề: Xóa IAM User thất bại - \u0026ldquo;User has attached policies\u0026rdquo;\nGiải pháp: Detach tất cả policies trước Vào IAM → Users → Chọn user → Permissions → Detach policies Vấn đề: PostgreSQL không dừng\nGiải pháp: Force kill process Trên macOS/Linux: sudo killall postgres Trên Windows: Dùng Task Manager để end các processes PostgreSQL Tùy chọn: Tiếp tục Học Nếu bạn muốn tiếp tục thử nghiệm:\nGiữ lại Các Tài nguyên: ✅ IAM User (với permissions tối thiểu) ✅ Bedrock model access (không tính phí khi không sử dụng) Những gì Bạn Có thể Làm Tiếp: Thêm nhiều documents vào Knowledge Base Triển khai thêm agent tools Deploy lên AWS Lambda cho serverless operation Thêm authentication và user management Tích hợp với hệ thống đặt xe thực Kết luận 🎉 Chúc mừng! Bạn đã thành công:\n✅ Xây dựng AI Agent sử dụng AWS Bedrock và Claude 3.5 Sonnet ✅ Tích hợp Knowledge Bases cho việc truy xuất tài liệu thông minh ✅ Tạo FastAPI backend với Strands Agent SDK ✅ Phát triển React frontend cho tương tác người dùng ✅ Kiểm thử tất cả tính năng end-to-end ✅ Dọn dẹp tài nguyên để tránh phí Những Điều Chính: AI Agents có thể tự động chọn tools và đưa ra quyết định AWS Bedrock đơn giản hóa truy cập đến các foundation models như Claude Knowledge Bases cho phép semantic search trên documents Strands SDK cung cấp framework cho xây dựng agent workflows FastAPI + React tạo ứng dụng AI full-stack hiện đại Các Bước Tiếp theo: Khám phá các Bedrock models khác (Llama 3, Mistral, v.v.) Học về RAG (Retrieval Augmented Generation) Xây dựng agent workflows phức tạp hơn Deploy lên production sử dụng các dịch vụ AWS "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Tuần 7: Chiến lược Di chuyển và Khôi phục Thảm họa (20/10 - 24/10) Mục tiêu: Chuyển đổi tải công việc từ On-Premise lên AWS và đảm bảo tính liên tục trong kinh doanh.\nCác công việc đã hoàn thành trong tuần: Ngày Thứ Nội dung Hoạt động chi tiết 20/10 2 VM Import/Export - Giả lập On-Prem với VirtualBox\n- Xuất VM ra định dạng .ova/.vmdk\n- Upload lên S3 và import thành AMI 21/10 3 Schema Conversion Tool (SCT) - Chuyển đổi Oracle schema sang Aurora PostgreSQL\n- Tự động convert tables, keys, indexes\n- Báo cáo Stored Procedures cần sửa thủ công 22/10 4 Database Migration Service (DMS) - Tạo Replication Instance\n- Cấu hình Source và Target endpoints\n- Chạy Full Load + CDC cho minimal downtime 23/10 5 Elastic Disaster Recovery (DRS) - Cài đặt Agent trên source servers\n- Continuous block-level replication lên AWS\n- Thực hiện DR Drill kiểm tra data integrity 24/10 6 AWS Backup - Tạo Backup Plan tập trung cho EC2, EBS, RDS, DynamoDB\n- Cấu hình Cross-Region Copy cho disaster protection Kết quả đạt được tuần 7: Server Migration:\nDi chuyển thành công VM từ VirtualBox lên EC2 Hiểu chiến lược Lift \u0026amp; Shift migration Database Migration:\nChuyển đổi heterogeneous database schema với SCT Di chuyển dữ liệu với minimal downtime dùng DMS CDC Disaster Recovery:\nTriển khai continuous replication với DRS Test recovery với DR Drill Đạt mục tiêu RPO/RTO thấp Backup Strategy:\nQuản lý backup tập trung với AWS Backup Cross-region copy cho regional disaster protection Khái niệm quan trọng:\n6 Rs of Migration (Rehost, Replatform, Refactor\u0026hellip;) RPO vs RTO trade-offs Continuous replication vs periodic backup "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Tuần 8: Tối ưu hóa Chi phí AWS \u0026amp; Khởi Động Dự Án Voltgo (27/10 - 31/10) Mục tiêu kép: Tiếp tục học tập về tối ưu hóa chi phí và mạng nâng cao trên AWS, đồng thời bắt đầu triển khai dự án Voltgo Frontend.\nPHẦN A: AWS - Tối ưu hóa Chi phí và Mạng nâng cao Ngày Thứ Nội dung Hoạt động chi tiết 27/10 2 Cost Explorer \u0026amp; CUR - Phân tích chi phí theo Service, Region, Tag\n- Kích hoạt Cost and Usage Report (CUR)\n- Truy vấn CUR với Glue và Athena 28/10 3 Right-Sizing - Sử dụng Compute Optimizer để nhận gợi ý\n- Tích hợp CloudWatch Agent cho memory metrics 29/10 4 Savings Plans \u0026amp; RIs - So sánh EC2 Instance vs Compute Savings Plans\n- Lên kế hoạch cam kết 1 năm cho base load 30/10 5 Transit Gateway - Triển khai hub-and-spoke network architecture\n- Cấu hình routing tables giữa các VPCs 31/10 6 VPC Flow Logs - Kích hoạt phân tích network traffic\n- Debug REJECT status để xác định blocking rules PHẦN B: Dự Án Voltgo - Vai trò Frontend Developer Từ tuần 8, tôi bắt đầu tham gia dự án Voltgo - nền tảng thuê xe điện. Với vai trò Frontend Developer, tôi chịu trách nhiệm xây dựng các giao diện chính: User, Login, Booking, Blog, Xe, Trạm.\nNgày Thứ Nội dung Hoạt động chi tiết 27/10 2 Project Kickoff - Hiểu yêu cầu business Voltgo\n- Xác định 6 modules chính: User, Login, Booking, Blog, Xe, Trạm\n- Tech stack: React.js + TypeScript 28/10 3 Thiết lập Môi trường - Khởi tạo project với Vite + TypeScript\n- Cấu trúc thư mục theo feature-based\n- Git branching strategy (feature/user, feature/booking\u0026hellip;) 29/10 4 Design System - Định nghĩa Voltgo theme colors (xanh lá - thân thiện môi trường)\n- Xây dựng shared components: VehicleCard, StationMarker, BookingCard 30/10 5 Routing \u0026amp; State Management - Cấu hình React Router v6 cho tất cả pages\n- Thiết lập Redux Toolkit slices cho từng module\n- Tạo Axios API layer 31/10 6 Layout Components - Xây dựng MainLayout với Header, Sidebar, Footer\n- Triển khai responsive navigation menu\n- Mobile hamburger menu Kết quả đạt được tuần 8: AWS Cost Optimization:\nPhân tích chi phí với Cost Explorer và CUR Xác định tài nguyên over-provisioned với Compute Optimizer Lên kế hoạch Savings Plans để giảm chi phí Voltgo Frontend:\nProject khởi tạo với React + TypeScript Design System định nghĩa với Voltgo branding Core layout và routing structure hoàn thành Sẵn sàng phát triển features từ Tuần 9 "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Tuần 9: Container AWS \u0026amp; Module Login/User Voltgo (03/11 - 07/11) Mục tiêu kép: Làm chủ Docker và các nền tảng điều phối container trên AWS, đồng thời xây dựng các trang Authentication cho Voltgo.\nPHẦN A: AWS - Công nghệ Container Ngày Thứ Nội dung Hoạt động chi tiết 03/11 2 Docker Fundamentals - Viết Dockerfile tối ưu (Multi-stage build)\n- Tạo ECR Repository\n- Push private image lên ECR 04/11 3 Amazon ECS \u0026amp; Fargate - Tạo Task Definition với CPU/RAM specs\n- Deploy ECS Service với Fargate\n- Tích hợp với Application Load Balancer 05/11 4 Amazon EKS Setup - Tạo EKS cluster với eksctl\n- Cấu hình Managed Node Groups\n- AWS tự động patching và upgrades 06/11 5 Deploy trên EKS - Viết K8s YAML manifests (Deployment, Service, Ingress)\n- Cài đặt AWS Load Balancer Controller\n- Auto-create ALB từ Ingress 07/11 6 CI/CD cho Containers - Xây dựng CI/CD Pipeline cho ECS/EKS\n- CodeCommit -\u0026gt; CodeBuild -\u0026gt; CodeDeploy\n- Blue/Green Deployment strategy PHẦN B: Voltgo - Module Login \u0026amp; User Ngày Thứ Nội dung Hoạt động chi tiết 03/11 2 Trang Đăng nhập - Xây dựng Login UI với React Hook Form + Yup validation\n- Remember Me với localStorage\n- Forgot Password flow với OTP 04/11 3 Trang Đăng ký - Form đăng ký: họ tên, email, SĐT, mật khẩu\n- Chọn loại user: Cá nhân/Doanh nghiệp\n- Checkbox điều khoản sử dụng 05/11 4 Authentication API - Kết nối POST /api/auth/login, /register\n- JWT token management với auto-refresh\n- Protected Routes cho Booking, Profile 06/11 5 Trang User Profile - Hiển thị avatar, họ tên, email, SĐT, địa chỉ\n- Form chỉnh sửa inline\n- Upload GPLX (bắt buộc để thuê xe) 07/11 6 Hoàn thiện Module User - Lịch sử booking trong trang User\n- Tính năng xe yêu thích\n- Quản lý phương thức thanh toán\n- Cài đặt thông báo Kết quả đạt được tuần 9: AWS Containers:\nTriển khai containers trên ECS Fargate (serverless) Thiết lập EKS cluster với managed node groups Xây dựng CI/CD pipeline cho container applications Voltgo Login \u0026amp; User:\nHoàn thành trang Login/Register với validation Tích hợp JWT authentication User profile với avatar, upload GPLX Lịch sử booking và phương thức thanh toán trong trang User "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Tuần 10: Serverless AWS \u0026amp; Module Xe/Trạm Voltgo (10/11 - 14/11) Mục tiêu kép: Xây dựng ứng dụng serverless trên AWS và phát triển tính năng Xe/Trạm cho Voltgo.\nPHẦN A: AWS - Kiến trúc Serverless Ngày Thứ Nội dung Hoạt động chi tiết 10/11 2 Bộ ba Serverless - Viết AWS Lambda cho CRUD operations\n- Tích hợp với DynamoDB\n- Xây dựng REST API với API Gateway 11/11 3 Serverless Auth \u0026amp; Security - Deploy Cognito Authorizer trên API Gateway\n- Cấu hình Custom Domains và SSL 12/11 4 Event-Driven Architecture - Xử lý orders với SQS và SNS\n- Cấu hình S3 triggers tạo thumbnail 13/11 5 Step Functions - Xây dựng workflow orchestration\n- Tạo quy trình phê duyệt: Kiểm tra kho -\u0026gt; Trừ tiền -\u0026gt; Gửi email 14/11 6 X-Ray Tracing - Kích hoạt distributed tracing\n- Quan sát service map: API Gateway -\u0026gt; Lambda -\u0026gt; DynamoDB PHẦN B: Voltgo - Module Xe \u0026amp; Trạm Ngày Thứ Nội dung Hoạt động chi tiết 10/11 2 Trang Danh sách Xe - Xây dựng danh sách xe với grid/list toggle\n- VehicleCard: hình ảnh, tên, loại, giá, pin, trạng thái\n- Filter theo loại, giá, phạm vi 11/11 3 Trang Chi tiết Xe - Image gallery, hiển thị thông số\n- Bảng giá (giờ, ngày, tuần)\n- Calendar lịch available, phần đánh giá 12/11 4 Trang Danh sách Trạm - Danh sách trạm với StationCard\n- Tích hợp Google Maps/Mapbox\n- Trạm gần nhất với Geolocation API 13/11 5 Trang Chi tiết Trạm - Thông tin đầy đủ: địa chỉ, giờ mở cửa, tiện ích\n- Xe available tại trạm\n- Trạng thái slot sạc, chỉ đường 14/11 6 Map View \u0026amp; Real-time - Bản đồ full-screen với tất cả trạm/xe\n- Custom markers (trạm=xanh, xe=vàng)\n- Marker clustering, cập nhật real-time Kết quả đạt được tuần 10: AWS Serverless:\nXây dựng serverless API hoàn chỉnh với Lambda, API Gateway, DynamoDB Triển khai event-driven architecture với SQS/SNS Điều phối workflows với Step Functions Kích hoạt distributed tracing với X-Ray Voltgo Xe \u0026amp; Trạm:\nHoàn thành trang Danh sách và Chi tiết Xe Trang Trạm với tích hợp bản đồ Cập nhật real-time trạng thái xe/trạm Geolocation cho trạm gần nhất "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Tuần 11: AWS Modernization \u0026amp; Module Booking/Blog Voltgo (17/11 - 21/11) Mục tiêu kép: Hiện đại hóa ứng dụng trên AWS và xây dựng tính năng Booking/Blog cho Voltgo.\nPHẦN A: AWS - Hiện đại hóa Ứng dụng Ngày Thứ Nội dung Hoạt động chi tiết 17/11 2 Microservices Architecture - Thiết kế patterns microservices\n- Triển khai API composition\n- Cấu hình service mesh cơ bản 18/11 3 CI/CD Pipeline - Setup CodePipeline cho tự động deploy\n- Cấu hình CodeBuild cho testing\n- Blue/Green deployment với CodeDeploy 19/11 4 Container Orchestration Nâng cao - EKS nâng cao: HPA, VPA\n- Triển khai service discovery\n- Cấu hình ingress controllers 20/11 5 Monitoring \u0026amp; Observability - CloudWatch Container Insights\n- Tạo custom dashboards\n- Setup alarms và notifications 21/11 6 DevOps Best Practices - Review Infrastructure as Code\n- Triển khai GitOps workflow\n- Security scanning trong pipeline PHẦN B: Voltgo - Module Booking \u0026amp; Blog Ngày Thứ Nội dung Hoạt động chi tiết 17/11 2 Booking Flow - Bước 1 - Xây dựng booking wizard nhiều bước\n- Bước 1: Chọn xe/trạm\n- Bước 2: Chọn khung giờ 18/11 3 Booking Flow - Bước 2 - Bước 3: Xác nhận thông tin user\n- Bước 4: Chọn phương thức thanh toán\n- Tính giá với khuyến mãi 19/11 4 Xác nhận Booking - Trang xác nhận booking\n- Tạo QR code để nhận xe\n- Gửi thông báo email/SMS 20/11 5 Trang Danh sách Blog - Danh sách blog với categories\n- Bài viết nổi bật/trending\n- Tìm kiếm và lọc theo tag 21/11 6 Trang Chi tiết Blog - Xem bài viết đầy đủ với rich content\n- Sidebar bài viết liên quan\n- Chia sẻ mạng xã hội, bình luận Kết quả đạt được tuần 11: AWS Modernization:\nThiết kế patterns kiến trúc microservices Xây dựng CI/CD pipeline hoàn chỉnh với CodePipeline Cấu hình EKS nâng cao với auto-scaling Monitoring toàn diện với Container Insights Voltgo Booking \u0026amp; Blog:\nHoàn thành booking flow với wizard 4 bước Tạo QR code để nhận xe Hệ thống blog với categories và tìm kiếm Tích hợp chia sẻ mạng xã hội "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Tuần 12: AWS Data Analytics \u0026amp; Testing/Deployment Voltgo (24/11 - 28/11) Mục tiêu kép: Xây dựng giải pháp phân tích dữ liệu trên AWS và chuẩn bị Voltgo cho testing và deployment.\nPHẦN A: AWS - Data Analytics \u0026amp; Machine Learning Ngày Thứ Nội dung Hoạt động chi tiết 24/11 2 Kiến trúc Data Lake - Thiết kế data lake với S3\n- Cấu hình Lake Formation\n- Setup data catalog với Glue 25/11 3 ETL \u0026amp; Xử lý Dữ liệu - Xây dựng ETL jobs với Glue\n- Real-time streaming với Kinesis\n- Pipelines chuyển đổi dữ liệu 26/11 4 Analytics \u0026amp; Visualization - Query dữ liệu với Athena\n- Xây dựng dashboards với QuickSight\n- Tạo reports và visualizations 27/11 5 Machine Learning Cơ bản - Tổng quan SageMaker\n- Train ML model đơn giản\n- Deploy model endpoint 28/11 6 AWS Well-Architected Review - Review tất cả pillars: Security, Cost, Performance, Reliability, Operations\n- Tài liệu hóa best practices đã áp dụng PHẦN B: Voltgo - Testing \u0026amp; Chuẩn bị Deployment Ngày Thứ Nội dung Hoạt động chi tiết 24/11 2 Unit Testing - Setup Jest/React Testing Library\n- Viết unit tests cho components\n- Test Redux slices và actions 25/11 3 Integration Testing - API integration tests\n- Test booking flow end-to-end\n- Mock service responses 26/11 4 E2E Testing \u0026amp; Performance - Setup Cypress cho E2E tests\n- Test critical user journeys\n- Performance audit với Lighthouse 27/11 5 Tối ưu hóa Build - Code splitting và lazy loading\n- Tối ưu hóa bundle size\n- Tối ưu hóa hình ảnh và assets 28/11 6 Setup Deployment - Cấu hình CI/CD pipeline\n- Setup môi trường staging\n- Quản lý environment variables Kết quả đạt được tuần 12: AWS Data Analytics:\nXây dựng kiến trúc data lake với S3 và Lake Formation Pipelines ETL với Glue và real-time streaming Dashboards analytics với Athena và QuickSight Làm quen với SageMaker ML Voltgo Testing \u0026amp; Deployment:\nBộ test toàn diện (unit, integration, E2E) Hoàn thành tối ưu hóa performance Cấu hình CI/CD pipeline Sẵn sàng cho production deployment "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/1-worklog/1.13-week13/","title":"Worklog Tuần 13","tags":[],"description":"","content":"Tuần 13: Tổng kết \u0026amp; Bàn giao Dự án (01/12 - 05/12) Mục tiêu kép: Hoàn thành chương trình AWS Cloud Journey và bàn giao dự án Voltgo.\nPHẦN A: AWS - Tổng kết \u0026amp; Chuẩn bị Chứng chỉ Ngày Thứ Nội dung Hoạt động chi tiết 01/12 2 Ôn tập Toàn diện - Ôn tập toàn bộ 12 tuần nội dung AWS\n- Xác định các lỗ hổng kiến thức\n- Tạo tóm tắt ghi chú học tập 02/12 3 AWS Location Service - Tích hợp AWS Location Service cho bản đồ\n- Cấu hình place indexes và geofencing\n- Triển khai các tính năng dựa trên vị trí 03/12 4 Showcase Kiến trúc - Trình bày kiến trúc 3-tier đã xây dựng\n- Demo giải pháp serverless\n- Trình bày container deployments 04/12 5 Phản tích Chi phí - Báo cáo chi phí cuối cùng cho tất cả resources\n- Áp dụng đề xuất tối ưu hóa\n- Tài liệu hóa chiến lược tiết kiệm chi phí 05/12 6 Hoàn thành Chương trình - Nộp tài liệu cuối cùng\n- Hoàn thành self-evaluation\n- Nhận chứng chỉ hoàn thành chương trình PHẦN B: Voltgo - Production Launch \u0026amp; Bàn giao Ngày Thứ Nội dung Hoạt động chi tiết 01/12 2 Sửa Bug Cuối cùng - Sửa các bug còn lại từ QA\n- Xử lý edge cases\n- Verify tất cả features hoạt động 02/12 3 Tính năng Tìm Trạm Gần Bạn - Triển khai tìm kiếm trạm gần vị trí hiện tại\n- Tích hợp AWS Location Service hiển thị bản đồ\n- Thêm Geolocation API lấy vị trí người dùng\n- Tính khoảng cách và hiển thị trạm gần nhất 02/12 3 Deploy Production - Deploy lên môi trường production\n- Cấu hình production domains\n- Setup SSL và security 03/12 4 Tài liệu - Viết tài liệu kỹ thuật\n- Tạo hướng dẫn sử dụng\n- Tài liệu hóa API endpoints 04/12 5 Chuyển giao Kiến thức - Tổ chức các buổi bàn giao\n- Hướng dẫn codebase cho team\n- Giải thích các quyết định kiến trúc 05/12 6 Hoàn thành Dự án - Demo cuối cùng cho stakeholders\n- Nộp deliverables dự án\n- Đóng các task dự án Kết quả đạt được tuần 13: AWS Cloud Journey:\nHoàn thành chương trình học AWS 13 tuần Xây dựng nhiều kiến trúc thực tế Tài liệu hóa best practices và bài học kinh nghiệm Voltgo Frontend Project:\nDeploy thành công lên production Hoàn thành tất cả modules: User, Login, Xe, Trạm, Booking, Blog Bàn giao tài liệu toàn diện Hoàn thành chuyển giao kiến thức TÓM TẮT HOÀN THÀNH CHƯƠNG TRÌNH Thành tựu AWS Cloud Journey: Thiết lập AWS Account \u0026amp; Quản lý IAM Kiến trúc VPC \u0026amp; Networking EC2 \u0026amp; Auto Scaling Giải pháp S3 Storage RDS \u0026amp; Quản lý Database Kiến trúc Bảo mật (WAF, KMS, Secrets Manager, GuardDuty) Container Services (ECS, EKS) Serverless (Lambda, API Gateway, DynamoDB) AWS Location Service (Bản đồ, Place Indexes, Geofencing) CI/CD \u0026amp; DevOps Practices Data Analytics \u0026amp; Machine Learning Cơ bản Thành tựu Voltgo Frontend: Project Setup với React.js, TypeScript, Redux Toolkit Design System \u0026amp; UI Components Module Quản lý User Authentication (Login/Register) Module Xe (Danh sách, Chi tiết, Bộ lọc) Module Trạm (Danh sách, Chi tiết, Tích hợp Bản đồ) Tính năng Tìm Trạm Gần Bạn (Tích hợp AWS Location Service) Quy trình Booking (Wizard nhiều bước, QR code) Hệ thống Blog (Danh sách, Chi tiết, Categories) Bộ Testing Toàn diện Deploy Production "},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://truongnguyenthaibinh77.github.io/Internship-Report/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]